# Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics

**著者**: Yaniv Nikankin, Anja Reusch, Aaron Mueller, Yonatan Belinkov  
**所属**: Technion – Israel Institute of Technology, Northeastern University  
**会議**: ICLR 2025 (Poster)  
**年**: 2024  
**arXiv**: [arXiv:2410.21272](https://arxiv.org/abs/2410.21272)  
**プロジェクトページ**: [https://technion-cs-nlp.github.io/llm-arithmetic-heuristics/](https://technion-cs-nlp.github.io/llm-arithmetic-heuristics/)

---

### 概要

本論文は、大規模言語モデル（LLM）が算術問題を解く際に、**堅牢なアルゴリズムでも記憶でもなく、「ヒューリスティックの集合（bag of heuristics）」**を使用していることを発見した研究です。因果分析とmechanistic interpretabilityを用いて、LLMの算術回路を特定し、個々のニューロンを高解像度で分析することで、各ニューロンが特定の数値パターンを識別して対応する答えを出力する単純なヒューリスティックを実装していることを明らかにしました。これらのヒューリスティックの無秩序な組み合わせが、モデルの算術精度の大部分を説明することが分かりました。

---

### 1. 新規性：この論文の最も大きな貢献と、既存研究と比べて何が新しいのか

**主な貢献**:

1. **ヒューリスティックベースの算術の実証**: LLMが算術を解く際に、堅牢なアルゴリズムでも記憶でもなく、ヒューリスティックの集合を使用していることを初めて実証しました。

2. **スパースなニューロンセットの発見**: 各層の約1%のニューロンが、算術行動の大部分を説明することを発見しました。

3. **個別ニューロンレベルの分析**: 個々のニューロンを高解像度で分析し、各ニューロンが特定の数値パターン（例: オペランドが特定の範囲内にある場合）を識別して対応する答えを出力する単純なヒューリスティックを実装していることを明らかにしました。

4. **訓練初期からの出現**: このメカニズムが訓練の初期段階から主要な算術アプローチとして出現することを示しました。

**既存研究との差分**:

- 従来の研究（Zhou et al., 2024; Stolfo et al., 2023; Zhang et al., 2024）は算術回路の存在を示していましたが、個々のニューロンがどのように機能しているかの詳細な分析は行われていませんでした。
- 本論文は、mechanistic interpretabilityの手法を用いて、ニューロンレベルでの詳細な分析を行った点が新規です。

---

### 2. 理論/手法の核心：提案されている理論や手法の要点

#### 2.1 算術回路の特定

**Activation Patching（活性化パッチング）**を用いて、算術行動に関与する回路を特定します。

- **手法**: 特定の層やニューロンの活性化を別の入力から取得した活性化で置き換え、モデルの出力への影響を測定します。
- **目的**: 算術問題の解決に重要な層やニューロンを特定します。

#### 2.2 個別ニューロンの分析

特定された回路内の個々のニューロンを高解像度で分析します。

**ヒューリスティックの分類**:

各ニューロンは、以下のような単純なヒューリスティックを実装しています：

1. **範囲ベースのヒューリスティック**: オペランドが特定の範囲内にある場合に活性化
   - 例: 「10-20の範囲の数値に対して特定の答えを出力」

2. **パターンベースのヒューリスティック**: 特定の数値パターンを識別
   - 例: 「末尾が5で終わる数値」「繰り上がりが発生するパターン」

3. **演算タイプベースのヒューリスティック**: 加算、減算、乗算などの演算タイプを識別

#### 2.3 ヒューリスティックの組み合わせ

これらのヒューリスティックは**無秩序に組み合わせられ**、モデルの算術精度の大部分を説明します。

- **スパース性**: 各層の約1%のニューロンが算術行動の大部分を説明
- **冗長性**: 複数のニューロンが類似したヒューリスティックを実装している可能性
- **協調**: 異なるヒューリスティックが協調して、より複雑な算術問題を解決

---

### 3. 実験結果と評価

#### 3.1 主要な発見

1. **スパースな回路**: 各層の約1%のニューロンが算術行動の大部分を説明することが確認されました。

2. **ヒューリスティックの種類**: ニューロンは、範囲ベース、パターンベース、演算タイプベースなど、様々な種類のヒューリスティックを実装していることが分かりました。

3. **訓練初期からの出現**: このメカニズムが訓練の初期段階から主要な算術アプローチとして出現することが確認されました。

4. **精度への寄与**: これらのヒューリスティックの無秩序な組み合わせが、モデルの算術精度の大部分を説明することが実証されました。

#### 3.2 因果的リンクの確立

Activation patchingを用いて、個々のニューロンとモデルの精度の間に因果的リンクを確立しました。

---

### 4. 関連研究との関係

本論文は、以下の研究と関連しています：

- **Zhou et al. (2024)**: Fourier featuresに関する研究
- **Stolfo et al. (2023)**: 算術回路に関する研究
- **Zhang et al. (2024)**: 算術回路に関する研究

本論文は、これらの研究のギャップを埋め、個々のニューロンがどのように機能しているかの詳細な分析を提供しています。

---

### 5. 意義と今後の展開

**意義**:

- **LLMの算術能力の理解**: LLMが算術を解く方法を理解するための新しい視点を提供しました。
- **Mechanistic Interpretability**: ニューロンレベルでの詳細な分析により、mechanistic interpretabilityの手法を発展させました。
- **アルゴリズム vs ヒューリスティック**: LLMが堅牢なアルゴリズムではなく、ヒューリスティックの集合を使用していることを示し、LLMの能力と限界を理解する上で重要な洞察を提供しました。

**今後の展開**:

- より大規模なモデルでの分析
- 異なる算術タスク（除算、平方根など）での分析
- ヒューリスティックの改善方法の開発
- より堅牢な算術能力を持つモデルの開発

---

### 参考文献

- Nikankin, Y., Reusch, A., Mueller, A., & Belinkov, Y. (2024). Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics. *arXiv preprint arXiv:2410.21272*.
- Zhou, D., et al. (2024). [Fourier featuresに関する研究]
- Stolfo, A., et al. (2023). [算術回路に関する研究]
- Zhang, Z., et al. (2024). [算術回路に関する研究]
