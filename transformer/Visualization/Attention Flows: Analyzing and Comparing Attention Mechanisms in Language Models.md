# Attention Flows: Analyzing and Comparing Attention Mechanisms in Language Models

**著者**: Joseph F. DeRose (Vanderbilt University), Jiayao Wang (Vanderbilt University), Matthew Berger (Vanderbilt University)  
**arXiv**: [arXiv:2009.07053](https://arxiv.org/abs/2009.07053)  
**発表年**: 2020年9月  
**掲載**: IEEE Transactions on Visualization and Computer Graphics

---

### 概要

この論文は、**Transformerベースの言語モデルにおける注意機構の可視化と比較**を支援する視覚分析アプローチ「**Attention Flows**」を提案した研究です。言語モデリングの進歩により、大規模な未ラベルテキストコーパスで事前学習され、特定のタスクにファインチューニングされる深層注意ベースモデルが広く使用されています。事前学習モデルの注意機構の理解は進んでいますが、**ターゲットタスクに訓練された際の注意機構の変化**についてはあまり理解されていません。本論文では、ファインチューニングにおける注意機構の変化を理解するための可視化ツールを提案し、層内、層間、および注意ヘッド間での注意のクエリ、追跡、比較を支援します。

---

### 論文の核心：ファインチューニング時の注意機構の変化

#### 1. 研究の背景と動機

Transformerベースの言語モデルは、以下のプロセスで使用されます：

- **事前学習**: 大規模な未ラベルテキストコーパスで汎用的な言語表現を学習
- **ファインチューニング**: 特定のタスク（感情分析、自然言語推論など）に適応

しかし、以下の問題が存在します：

- **注意機構の変化の理解不足**: ファインチューニング時に注意機構がどのように変化するかが不明
- **可視化ツールの限界**: 既存の可視化ツールは、事前学習モデルとファインチューニングモデルの比較を十分にサポートしていない
- **層間の注意の流れ**: 複数層にわたる注意の流れを追跡する方法が不足

#### 2. Attention Flowsの設計思想

Attention Flowsは、以下の設計思想に基づいています：

- **分類決定の理解**: 最深層での分類ベースの注意を中心に、それ以前の層からの注意が入力単語間でどのように流れるかを可視化
- **単一モデルの分析**: 単一モデルの注意機構を詳細に分析
- **モデル間の比較**: 事前学習モデルとファインチューニングモデルの類似点と相違点を視覚的に比較

---

### Attention Flowsのアプローチ

#### 1. 可視化の設計

Attention Flowsは、以下の主要な可視化コンポーネントで構成されます：

##### 分類注意の可視化（Classification Attention）
- **最深層の注意**: 分類タスクにおける最終層の注意重みを可視化
- **単語への注目度**: 各入力単語が分類決定にどの程度寄与しているかを表示

##### 注意の流れ（Attention Flow）
- **層間の伝播**: 各層から次の層への注意の流れを追跡
- **単語間の依存関係**: 注意がどのように単語間で伝播するかを可視化

##### 注意ヘッドの比較
- **ヘッド間の違い**: 異なる注意ヘッドがどのようなパターンを学習しているかを比較
- **ヘッドの役割**: 各ヘッドがどのような言語的機能を担っているかを理解

#### 2. クエリとフィルタリング機能

Attention Flowsは、以下のクエリとフィルタリング機能を提供します：

- **単語ベースのクエリ**: 特定の単語に注目している層やヘッドを検索
- **注意強度のフィルタリング**: 特定の注意強度以上の接続のみを表示
- **層の選択**: 特定の層や層範囲に焦点を当てた分析

#### 3. 比較機能

事前学習モデルとファインチューニングモデルの比較を支援します：

- **注意分布の比較**: 同じ入力に対する注意分布の違いを可視化
- **変化の追跡**: ファインチューニングによってどの部分の注意が変化したかを特定
- **類似性の測定**: モデル間の注意パターンの類似性を定量化

---

### 技術的な詳細

#### 1. 注意の流れの計算

Attention Flowsでは、層間の注意の流れを以下のように計算します：

##### 注意重みの集約
各層の注意重みを集約し、入力トークンから出力トークンへの情報の流れを追跡します。

##### 注意の伝播
複数層にわたる注意の伝播を計算するため、以下のアプローチを使用します：

- **直接的な注意**: 各層での直接的な注意重み
- **累積的な注意**: 前の層からの注意を考慮した累積的な注意重み
- **注意の流れ**: 入力トークンから最終出力への注意の流れを追跡

#### 2. 分類注意の計算

分類タスクでは、最終層の注意重みを分類決定に関連付けます：

- **クラス固有の注意**: 各クラスに対する注意の分布を計算
- **決定要因の特定**: 分類決定に最も寄与している単語を特定
- **注意の可視化**: 分類注意を直感的に理解できる形式で可視化

#### 3. 視覚化の実装

Attention Flowsは、以下の視覚化技術を使用します：

- **サンキーダイアグラム**: 注意の流れをサンキーダイアグラムで表現
- **ヒートマップ**: 注意重みをヒートマップで表示
- **ネットワーク図**: 単語間の注意関係をネットワーク図で表現
- **インタラクティブな探索**: ユーザーがインタラクティブに注意パターンを探索できる機能

---

### 実験と評価

#### 1. 実験設定

論文では、以下のタスクで実験が行われました：

- **感情分析（Sentiment Analysis）**: テキストの感情を分類
- **自然言語推論（Natural Language Inference）**: 前提と仮説の関係を推論
- **質問応答（Question Answering）**: 質問に対する回答を生成

##### 使用モデル
- **BERT**: Bidirectional Encoder Representations from Transformers
- **RoBERTa**: Robustly Optimized BERT Pretraining Approach
- その他のTransformerベースモデル

#### 2. 主要な発見

実験結果から、以下の重要な発見が得られました：

##### ファインチューニング時の注意の変化
- **注意の再配分**: ファインチューニングにより、注意がタスクに関連する単語に再配分される
- **層ごとの変化**: 浅い層と深い層で異なるパターンの変化が観察される
- **ヘッドの専門化**: 特定のヘッドがタスク固有の機能を担うようになる

##### 注意パターンの理解
- **文法的な注意**: 浅い層では文法的な関係に注意が向く
- **意味的な注意**: 深い層では意味的な関係に注意が向く
- **タスク固有の注意**: ファインチューニング後は、タスクに関連する単語に注意が集中

##### モデル間の比較
- **事前学習モデル**: 汎用的な言語パターンに注意が向く
- **ファインチューニングモデル**: タスク固有のパターンに注意が向く
- **変化のパターン**: タスクによって異なる注意の変化パターンが観察される

#### 3. ユーザビリティ評価

Attention Flowsの有用性を評価するため、以下の評価が行われました：

- **専門家による評価**: NLP研究者によるツールの有用性評価
- **ケーススタディ**: 具体的なタスクでの使用例の提示
- **定性的なフィードバック**: ユーザーからの定性的なフィードバックの収集

---

### 論文の意義と貢献

#### 1. ファインチューニングの理解

Attention Flowsは、ファインチューニング時の注意機構の変化を理解するための初めての包括的な可視化ツールの一つです：

- **変化の可視化**: 事前学習からファインチューニングへの注意の変化を可視化
- **層間の理解**: 複数層にわたる注意の流れを理解
- **タスク固有の洞察**: タスクごとの注意パターンの違いを発見

#### 2. 視覚分析のアプローチ

本論文は、機械学習モデルの解釈可能性における視覚分析の重要性を示しています：

- **インタラクティブな探索**: ユーザーが能動的に注意パターンを探索できる
- **多角的な視点**: 層、ヘッド、単語など、様々な視点から注意を分析
- **比較分析**: モデル間の比較を通じた深い理解

#### 3. 実用的なツール

Attention Flowsは、以下の実用的な応用が可能です：

- **モデルのデバッグ**: モデルが期待通りに動作しているかを検証
- **バイアスの発見**: モデルが不適切なパターンに注意を向けているかを発見
- **モデルの改善**: 注意パターンからモデルの改善方法を発見

---

### 技術的な革新点

#### 1. 注意の流れの追跡

従来の可視化ツールは、各層の注意を独立に可視化していましたが、Attention Flowsは以下を実現しました：

- **層間の接続**: 層間の注意の流れを追跡
- **累積的な理解**: 複数層にわたる注意の累積的な効果を理解
- **情報の伝播**: 入力から出力への情報の伝播を可視化

#### 2. 分類注意の可視化

分類タスクにおける注意の可視化を改善しました：

- **クラス固有の注意**: 各クラスに対する注意の分布を可視化
- **決定要因の特定**: 分類決定に寄与している単語を特定
- **直感的な理解**: 分類注意を直感的に理解できる形式で提示

#### 3. モデル間の比較

事前学習モデルとファインチューニングモデルの比較を支援します：

- **類似性の測定**: モデル間の注意パターンの類似性を定量化
- **変化の特定**: ファインチューニングによって変化した部分を特定
- **視覚的な比較**: 視覚的に分かりやすい形式で比較結果を提示

---

### 限界と今後の課題

#### 1. 計算コスト

大規模なモデルや長い入力テキストの場合、計算コストが高くなる可能性があります：

- **注意重みの計算**: 全層、全ヘッドの注意重みを計算する必要がある
- **可視化の生成**: 複雑な可視化の生成に時間がかかる場合がある

#### 2. 解釈の難しさ

注意の流れの解釈は、以下の理由で困難な場合があります：

- **複雑性**: 複数層、複数ヘッドの注意パターンは複雑
- **主観性**: 注意パターンの解釈には主観的な要素が含まれる
- **文脈依存性**: 注意パターンは入力テキストに強く依存

#### 3. 評価の難しさ

可視化ツールの評価は、以下の理由で困難です：

- **定量的な評価**: 可視化の質を定量的に評価する方法が限られている
- **ユーザビリティ**: ユーザビリティの評価には時間とリソースが必要
- **汎用性**: 様々なタスクやモデルに適用可能かどうかの検証が必要

---

### 実践的な示唆

#### 1. モデルの理解と検証

Attention Flowsを使用することで、以下のことが可能になります：

- **注意パターンの理解**: モデルがどのようなパターンに注意を向けているかを理解
- **期待との一致**: モデルの注意パターンが期待と一致するかを検証
- **異常の検出**: 予期しない注意パターンを発見

#### 2. モデルの改善

注意パターンから、以下のような改善方法を発見できます：

- **データの不足**: 重要なパターンがデータに不足している場合の特定
- **アーキテクチャの改善**: より良い注意パターンを学習できるアーキテクチャの設計
- **正則化**: 不適切な注意パターンを抑制する正則化手法の設計

#### 3. 教育と研究

Attention Flowsは、以下の教育・研究目的に活用できます：

- **教育ツール**: Transformerの動作を理解するための教育ツール
- **研究の支援**: 注意機構に関する研究を支援
- **コミュニケーション**: モデルの動作を非専門家に説明するためのツール

---

### まとめ

Attention Flowsは、Transformerベースの言語モデルにおける注意機構の可視化と比較を支援する画期的な視覚分析ツールです。ファインチューニング時の注意機構の変化を理解し、層間、ヘッド間、モデル間での注意パターンを比較することで、モデルの動作を深く理解できるようになります。このツールは、NLPモデルの解釈可能性を大幅に向上させ、モデルの理解、検証、改善を支援します。

Attention Flowsは、視覚分析のアプローチが機械学習モデルの解釈可能性において重要な役割を果たすことを示しており、今後の研究では、計算効率の向上、より直感的な可視化、評価方法の改善などが重要な課題となるでしょう。
