# ExBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models

**著者**: Benjamin Hoover, Hendrik Strobelt, Sebastian Gehrmann  
**公開**: ACL 2020 (System Demonstrations)  
**リンク**: [exBERT.net](https://exbert.net/) | [GitHub](https://github.com/bhoov/exbert) | [論文](https://www.aclweb.org/anthology/2020.acl-demos.22/)

---

## 概要

ExBERTは、Transformerモデル（特にBERT）が学習した**内部表現を視覚的に探索・分析**するためのインタラクティブなWebベースのツールです。BERTの各層で獲得された埋め込み表現を、意味空間上で可視化し、モデルがどのように言語を理解しているかを直感的に理解できるようにします。

## 主な機能と特徴

### 1. トークンごとの埋め込みベクトルの近傍探索

ExBERTは、BERTの各層で計算された埋め込みベクトルを可視化し、意味的に類似したトークンが埋め込み空間上で近くに配置されることを確認できます。

**探索機能**:
- 任意のトークンを選択し、その近傍にあるトークンを表示
- 層ごとの埋め込みの変化を観察
- 意味的・文法的に類似したトークンがどのようにクラスタリングされているかを確認

### 2. Attentionに基づく文脈依存表現の変化

BERTの埋め込みは、文脈に依存して変化します。ExBERTは、同じ単語が異なる文脈でどのように表現されるかを可視化します。

**可視化される内容**:
- 同一トークンが異なる文脈でどのように埋め込みが変化するか
- 文脈情報が各層でどのように統合されるか
- 多義語が文脈に応じてどのように区別されるか

### 3. 類似表現・意味空間の可視化

ExBERTは、高次元の埋め込み空間を**次元削減**（t-SNE、UMAPなど）を用いて2次元または3次元に可視化します。

**可視化の特徴**:
- 意味的に類似したトークンが近くに配置される
- 文法的に類似したトークン（例：動詞の過去形）がクラスタを形成
- 層が深くなるにつれて、より抽象的な意味表現が獲得されることを確認

### 4. 層ごとの表現の進化

BERTの12層（baseモデル）または24層（largeモデル）を通して、表現がどのように進化するかを追跡できます。

**観察できる変化**:
- **浅い層**: 字句的な類似性（文字列の類似性）
- **中間層**: 文法的な類似性（品詞、構文）
- **深い層**: 意味的な類似性（意味的関係、概念）

## 技術的な実装

### 埋め込みの抽出

ExBERTは、BERTモデルにテキストを入力し、各層の出力（隠れ状態）を取得します。

**処理の流れ**:
1. 入力テキストをトークン化
2. 各Transformer層の出力を取得
3. 埋め込みベクトルを抽出
4. 次元削減を適用して可視化

### インタラクティブな可視化

ExBERTは、Webベースのインタラクティブなインターフェースを提供します。

**技術スタック**:
- **バックエンド**: Python（PyTorch、Transformersライブラリ）
- **フロントエンド**: JavaScript（D3.js、Three.js）
- **可視化**: t-SNE、UMAPによる次元削減

### 対応モデル

- BERT-base-uncased
- BERT-large-uncased
- その他のBERT変種

## 使用例と応用

### 1. モデルの理解

BERTがどのように言語を理解しているかを、視覚的に理解できます。

**例**:
- 「bank」という単語が、文脈に応じて「銀行」と「川岸」のどちらの意味で使われているかを確認
- 動詞の活用形（run, runs, ran, running）が意味空間上でどのように配置されているかを観察

### 2. モデルのデバッグ

予期しない予測結果が得られた場合、埋め込み空間を確認することで、モデルがどのように入力を解釈しているかを理解できます。

### 3. 研究への応用

多くの研究者が、ExBERTを用いてBERTの内部表現に関する研究を進めています。

**研究例**:
- BERTが獲得する言語知識の分析
- 多言語BERTの言語間の類似性の調査
- ファインチューニングによる表現の変化の観察

## 他のツールとの比較

### bertvizとの違い

- **bertviz**: Attention重みの可視化に特化
- **ExBERT**: 埋め込み空間の可視化に特化

### eccoとの違い

- **ecco**: 生成過程と内部表現の探索
- **ExBERT**: 埋め込み空間ベースの探索

## 重要性と意義

### 1. BERT理解の促進

ExBERTは、BERTの内部表現を**視覚的に理解**するための最初の実用的なツールの一つです。多くの研究者が、このツールを通じてBERTの動作を理解してきました。

### 2. 教育ツールとしての価値

BERTの内部表現を理解するための教育ツールとしても広く活用されています。

### 3. 研究への貢献

多くの研究者が、ExBERTを用いてBERTの内部表現に関する新たな知見を得ています。

## まとめ

ExBERTは、BERTの内部表現を視覚的に探索するための強力なツールです。埋め込み空間ベースの可視化により、モデルがどのように言語を理解しているかを直感的に理解できる点が最大の特徴です。BERTの理解を深めるための重要なツールとして、多くの研究者や開発者に活用されています。
