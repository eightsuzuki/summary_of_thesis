# xPos

**出典**: Scaling Laws for Neural Language Models — Sun et al., 2022（付録: xPos）  
**リンク**: [arXiv:2212.10554](https://arxiv.org/abs/2212.10554)

---

### 概要
RoPE の長文外挿時の数値不安定・減衰挙動を緩和するため、周波数スケーリングと減衰（decay）を導入し、位相回転のダイナミクスを安定化。より長いコンテキストでの一貫した注意スケールを狙う。

---

### 仕組み（概念）
- RoPE の角周波数や回転強度に対し、位置に依存するスケーリング・減衰を付与。
- 大きな位置差 \(|p-p'|\) でも注意ロジットが過剰に減衰・発散しないように制御。

---

### 特徴
- **長所**: RoPE の外挿（学習長外）挙動を安定化。長文での性能維持に寄与。
- **短所**: 追加ハイパラと実装の複雑化（補間・減衰関数の設計）。

---

### 実装メモ
- 既存 RoPE 実装に対し、周波数補間・減衰項を組み込む。係数は経験的に調整。
- YaRN など他の補間法と目的が近く、選好・併用は実験で比較。

---

### 関連
- 基礎: `RoPE: Rotary Position Embedding.md`
- 代替/補間: `YaRN: Yet Another RoPE Extension.md`
