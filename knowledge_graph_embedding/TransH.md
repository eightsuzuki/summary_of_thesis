# TransH: ハイパープレーン上での並進による知識グラフ埋め込み

**著者**:
* Zhen Wang (Department of Information Science and Technology, Sun Yat-sen University, Guangzhou, China)
* Jianwen Zhang (Microsoft Research, Beijing, China)
* Jianlin Feng (Department of Information Science and Technology, Sun Yat-sen University, Guangzhou, China)
* Zheng Chen (Microsoft Research, Beijing, China)

**出版**: Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence (AAAI 2014)
**URL**: [Knowledge Graph Embedding by Translating on Hyperplanes](https://cdn.aaai.org/ojs/8870/8870-13-12398-1-2-20201228.pdf)

---

### 概要

この論文では、大規模な知識グラフを連続的なベクトル空間に埋め込むための手法「TransH（Translating on Hyperplanes）」を提案しています。TransHは、先行研究であるTransEのシンプルさと効率性を維持しつつ、TransEが苦手としていた関係の多様なプロパティ（自己反射的、1対多、多対1、多対多など）をより効果的にモデル化することを目的としています。TransHは、各関係を単一の並進ベクトルとして扱う代わりに、**関係固有のハイパープレーン**と、そのハイパープレーン上での並進操作によって表現します。これにより、モデルの表現能力と効率性の間で良好なトレードオフを実現し、リンク予測においてTransEを上回る顕著な改善を達成しています。

### 新規性

TransHの最も重要な新規性は、**関係をハイパープレーンと、そのハイパープレーン上での並進としてモデル化した**点にあります。TransEは関係を単純な並進ベクトルとして扱っていましたが、これにより以下のような問題が生じていました。

* **多様な関係プロパティへの対応不足**: TransEは、1つのエンティティが異なる関係において複数の役割を持つ場合（例：「首都」関係では国と都市が1対1だが、「出身地」関係では1対多になる場合）、エンティティの埋め込みが固定であるためにこれを適切に表現できませんでした。特に、自己反射的（reflexive）、1対多（one-to-many）、多対1（many-to-one）、多対多（many-to-many）の関係において、TransEは性能の限界を示していました。
* **表現能力の制限**: 1つのエンティティ埋め込みが複数の異なる関係において同じ意味を持つと仮定されるため、エンティティの文脈に応じたセマンティクスを捉えきれない問題がありました。

TransHは、これらの問題に対して、エンティティを関係固有のハイパープレーンに投影することで、**エンティティが関係ごとに異なる表現を持つことを可能にしました**。これにより、モデルの複雑性をTransEと同程度に保ちつつ、関係の多様なマッピングプロパティをより正確に捉えることが可能になりました。

### 理論/手法の核心

TransHモデルでは、各関係 $r \in \mathcal{L}$ が2つのベクトルによって特徴付けられます。

1.  **ハイパープレーンの法線ベクトル**: $\mathbf{w}_r \in \mathbb{R}^k$。このベクトルは、関係 $r$ に関連するハイパープレーンの方向を定義します。制約として、$||\mathbf{w}_r||_2 = 1$ が課せられます。
2.  **ハイパープレーン上の並進ベクトル**: $\mathbf{d}_r \in \mathbb{R}^k$。このベクトルは、関係 $r$ のセマンティクスを表す並進操作を、定義されたハイパープレーン上で行います。

**エンティティの投影**:
トリプル $(h, r, t)$ が与えられたとき、ヘッドエンティティの埋め込み $\mathbf{h} \in \mathbb{R}^k$ とテールエンティティの埋め込み $\mathbf{t} \in \mathbb{R}^k$ は、まず関係 $r$ に対応するハイパープレーンに投影されます。投影されたエンティティの表現は以下のようになります。

* ヘッドエンティティの投影:
    $$
    \mathbf{h}_{\perp r} = \mathbf{h} - \mathbf{w}_r^T \mathbf{h} \mathbf{w}_r
    $$
* テールエンティティの投影:
    $$
    \mathbf{t}_{\perp r} = \mathbf{t} - \mathbf{w}_r^T \mathbf{t} \mathbf{w}_r
    $$
    ここで、$\mathbf{w}_r^T \mathbf{h}$ はベクトル $\mathbf{h}$ を法線ベクトル $\mathbf{w}_r$ に投影したスカラー値です。この操作により、エンティティの埋め込みはハイパープレーンに沿った成分のみを持つようになります。

**スコアリング関数**:
トリプル $(h, r, t)$ の適合度（スコア）は、投影されたエンティティと並進ベクトルを用いて以下のように定義されます。TransEと同様に、このスコアが小さいほどトリプルは正しいとみなされます。

$$f_r(\mathbf{h}, \mathbf{t}) = ||(\mathbf{h} - \mathbf{w}_r^T \mathbf{h} \mathbf{w}_r) + \mathbf{d}_r - (\mathbf{t} - \mathbf{w}_r^T \mathbf{t} \mathbf{w}_r)||_2^2$$
またはL1ノルムも使用可能です。
$$f_r(\mathbf{h}, \mathbf{t}) = ||(\mathbf{h} - \mathbf{w}_r^T \mathbf{h} \mathbf{w}_r) + \mathbf{d}_r - (\mathbf{t} - \mathbf{w}_r^T \mathbf{t} \mathbf{w}_r)||_1$$
ここで、$||\cdot||_2^2$ または $||\cdot||_1$ は、それぞれL2ノルムの二乗またはL1ノルムを表します。

**損失関数**:
モデルは、TransEと同様にマージンベースのランキング基準を用いて学習されます。これは、正しいトリプルのスコアを低く、破損した（負例の）トリプルのスコアを高くすることで、正しいトリプルと負例のトリプルの間にマージン $\gamma$ を設けることを目的とします。

$$\mathcal{L} = \sum_{(h, r, t) \in S} \sum_{(h', r', t') \in S'_{(h,r,t)}} [\gamma + f_r(\mathbf{h}, \mathbf{t}) - f_{r'}(\mathbf{h'}, \mathbf{t'})]_+$$
ここで、
* $S$: 正しいトリプルの訓練セット。
* $S'_{(h,r,t)}$: 破損したトリプルのセット。TransEと同様に、正しいトリプルのヘッドまたはテールをランダムなエンティティで置き換えることで生成されます。
* $[x]_+ = \max(0, x)$: ヒンジ損失。
* $\gamma > 0$: マージンハイパーパラメータ。

**制約**:
エンティティの埋め込みベクトル $\mathbf{e}$ には $||e||_2 \le 1$ の制約が課せられます。また、関係のハイパープレーンの法線ベクトル $\mathbf{w}_r$ には $||w_r||_2 = 1$ の制約が課せられます。

### 「キモ」と重要性

TransHの「キモ」は、**エンティティを関係固有のハイパープレーンに投影し、そのハイパープレーン上で並進を行う**というメカニズムにあります。このアプローチにより、以下の重要な影響と利点をもたらしました。

* **関係の多様なプロパティへの対応**: TransEが苦手としていた1対多、多対1、多対多、自己反射的などの複雑な関係を、エンティティの「異なる視点（異なる投影）」を導入することで効果的にモデル化できるようになりました。これにより、より現実の知識グラフの複雑な構造を正確に捉えることが可能になりました。例えば、「出身地」のような1対多の関係では、ある人が複数の出身地を持つ場合、その人をそれぞれの出身地の文脈で異なる投影で表現できます。
* **表現能力と効率性のバランス**: TransHは、各関係にハイパープレーンの法線ベクトルと並進ベクトルの2つのベクトルを導入するだけで、TransEと比較してモデルの複雑度を大幅に増やすことなく、表現能力を向上させました。これにより、大規模な知識グラフに対しても、効率的な学習と優れた予測性能を両立させることが可能になりました。
* **知識グラフ埋め込み研究の進展**: TransHは、TransEのシンプルな枠組みを維持しつつ、その限界を克服する具体的な方法を示したことで、知識グラフ埋め込み研究における重要な一歩となりました。これにより、関係の複雑性をより深く理解し、モデル化するための後続の研究（TransR, TransDなど）に道を開きました。

TransHは、知識グラフの補完、リンク予測、トリプル分類などのタスクにおいて、TransEと比較して顕著な性能改善を実証しました。その革新的なアプローチは、知識グラフのセマンティックな構造をより正確に捉え、実用的なアプリケーションにおける知識グラフの活用をさらに推し進める上で極めて重要な貢献をしました。
