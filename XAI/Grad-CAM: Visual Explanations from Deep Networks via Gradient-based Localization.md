# Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization

**著者**: Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, Dhruv Batra  
**公開**: arXiv 2016（IJCV 2019 拡張版）  
**DOI**: 10.48550/arXiv.1610.02391  
**リンク**: [arXiv:1610.02391](https://arxiv.org/abs/1610.02391)

本論文は、CNN系モデルの幅広いクラスに対して、クラス判別的な粗い局在ヒートマップを生成する **Grad-CAM**（Gradient-weighted Class Activation Mapping）を提案します。最終畳み込み層の特徴マップに対するクラススコアの勾配を用いて、重要な空間領域を強調します。アーキテクチャ変更や再学習は不要で、分類・キャプション・VQA・強化学習など多様な設定に適用可能です。

---

### 1. 新規性：この論文の貢献と既存研究との差分

- **CAMの一般化**: Global Average Pooling（GAP）と線形分類器に依存するCAMを、最終畳み込み層の勾配情報で一般化し、任意のCNNに適用可能に。
- **クラス判別的ローカライゼーション**: クラス依存の勾配重みで特徴マップを線形合成し、重要領域を特定。
- **高解像度化（Guided Grad-CAM）**: Guided Backpropagationと組み合わせて、クラス判別性と高周波詳細の両立を実現。
- **人間実験による検証**: 失敗解析・頑健性・バイアス同定・ユーザ信頼の改善を実証。

---

### 2. 理論/手法の核心：数式できっちり定式化

#### 記法
- **最終畳み込み層**のチャネル別特徴マップを \(A^{k} \in \mathbb{R}^{H\times W}\)（\(k=1,\dots,K\)）。
- ターゲットクラス \(c\) のスコア（ロジット）を \(y^{c}(x)\) とする。
- 画素和の規格化定数 \(Z = H\times W\)。

**重要**: Grad-CAM（およびCAM）は**最終畳み込み層**のチャネルのみを使用します。中間層のチャネルは使用しません。理由は以下の通りです：
1. **空間分解能**: 最終畳み込み層は、高次抽象的特徴を保持しつつ、まだ空間情報（位置情報）が残っている
2. **クラス判別性**: 最終畳み込み層の特徴は、クラス判別に直接寄与する高次特徴を表現している
3. **実用性**: より浅い層は低次特徴（エッジ、テクスチャなど）を捉えており、クラス判別には適さない。より深い層（全結合層以降）は空間情報が失われている

#### 2.1 勾配重みとクラスマップ
勾配を空間平均したチャネル重み：
\[
\alpha_k^{c} \;=\; \frac{1}{Z} \sum_{i=1}^{H} \sum_{j=1}^{W} \frac{\partial y^{c}}{\partial A^{k}_{ij}}.
\]
クラス \(c\) に対するGrad-CAMマップ（粗い局在マップ）：
\[
L^{c}_{\text{Grad-CAM}} \;=\; \operatorname{ReLU}\Bigl( \sum_{k=1}^{K} \alpha_k^{c} \, A^{k} \Bigr).
\]
- ReLUは、クラスに正の影響を与える部位を強調（負貢献を抑制）。
- 実装上、\(L^{c}_{\text{Grad-CAM}}\) を入力画像解像度へ双一次補間でアップサンプルして可視化。

#### 2.2 Guided Grad-CAM（高解像度化）
Guided Backpropagationで得た高周波・エッジ情報の勾配マップ \(G\) と要素積：
\[
\text{Guided-Grad-CAM}^{c} \;=\; \text{Upsample}\bigl(L^{c}_{\text{Grad-CAM}}\bigr) \;\odot\; G.
\]
これにより、クラス判別性（Grad-CAM）と高分解能（Guided BP）の長所を統合。

#### 2.3 CAMとGrad-CAMの詳細比較

**CAM（Class Activation Mapping）**と**Grad-CAM（Gradient-weighted Class Activation Mapping）**の主な違い：

| 項目 | CAM | Grad-CAM |
|------|-----|----------|
| **重みの取得方法** | 学習済みの線形分類層の重み \(w_k^c\) を直接使用 | 勾配の空間平均 \(\alpha_k^c = \frac{1}{Z}\sum_{i,j} \frac{\partial y^c}{\partial A^k_{ij}}\) を計算 |
| **アーキテクチャ要件** | **必須**: GAP + 線形分類層（全結合層を削除） | **不要**: 既存の任意のCNNアーキテクチャに適用可能 |
| **再学習** | アーキテクチャ変更のため再学習が必要 | 学習済みモデルにそのまま適用可能（再学習不要） |
| **適用範囲** | GAP + 線形分類層を持つモデルのみ | 任意のCNN（ResNet、VGG、Inceptionなど）に適用可能 |
| **数式** | \(M^c(i,j) = \sum_k w_k^c A^k_{ij}\) | \(L^c_{\text{Grad-CAM}} = \operatorname{ReLU}(\sum_k \alpha_k^c A^k)\) |
| **ReLUの使用** | なし（負の値も含む） | あり（正の寄与のみを強調） |
| **理論的根拠** | GAPの線形性を利用した直接的な重み適用 | 勾配による感度解析（どの特徴マップがクラススコアに敏感か） |

**数式的な関係**:
- CAMでは、クラススコアが \(y^c = \sum_k w_k^c F_k + b^c\)（\(F_k\)はGAP後の値）と線形なので、重み \(w_k^c\) を直接特徴マップに適用できる。
- Grad-CAMでは、勾配 \(\frac{\partial y^c}{\partial A^k_{ij}}\) を空間平均することで、各チャネル \(k\) がクラス \(c\) のスコアにどれだけ敏感かを定量化し、それを重みとして使用する。

**実用上の違い**:
1. **CAM**: モデルを最初からGAP + 線形分類層で設計する必要がある。既存のモデルには適用できない。
2. **Grad-CAM**: 既存の学習済みモデル（ResNet、VGG、DenseNetなど）にそのまま適用できる。より汎用的。

**なぜGrad-CAMがCAMの一般化か**:
- CAMは「GAP + 線形分類」という特殊な構造でのみ機能する。
- Grad-CAMは勾配情報を使うことで、任意のCNNアーキテクチャで「各チャネルがクラスにどれだけ寄与するか」を推定できる。
- 数学的には、GAP + 線形分類の場合、勾配 \(\alpha_k^c\) は学習済み重み \(w_k^c\) と一致する（または比例する）ため、Grad-CAMはCAMを一般化した手法と言える。

#### 2.4 Grad-CAMがアーキテクチャ変更問題をどう解決したか

**CAMの問題点（再確認）**:
- 全結合層では、クラススコアが \(y^c = \sum_{k,i,j} w_{k,i,j}^{c} A^{k}_{ij} + b^{c}\) と表され、位置 \((i,j)\) ごとに異なる重み \(w_{k,i,j}^{c}\) が存在する
- このため、「チャネルごとに1つの重み」という構造がなく、CAMを生成できない
- 解決にはGAP + 線形分類層へのアーキテクチャ変更が必要

**Grad-CAMの解決方法: 勾配による感度解析**

Grad-CAMは、**学習済みの重みパラメータに依存せず、勾配情報を使って各チャネルの重要性を直接計算**します。

**全結合層がある場合でも機能する理由**:

1. **勾配の意味**: 勾配 \(\frac{\partial y^c}{\partial A^{k}_{ij}}\) は、「特徴マップ \(A^{k}_{ij}\) を微小に変化させたとき、クラススコア \(y^c\) がどれだけ変化するか」を表す。

2. **空間平均による要約**: 各位置 \((i,j)\) での勾配を空間平均することで、チャネル \(k\) 全体の重要性を1つの値に要約：
   \[
   \alpha_k^{c} = \frac{1}{Z} \sum_{i=1}^{H} \sum_{j=1}^{W} \frac{\partial y^c}{\partial A^{k}_{ij}}.
   \]
   この \(\alpha_k^{c}\) は「チャネル \(k\) がクラス \(c\) のスコアにどれだけ敏感か（寄与するか）」を定量化する。

3. **全結合層があっても計算可能**: 
   - 全結合層の重み \(w_{k,i,j}^{c}\) が位置依存でも、勾配 \(\frac{\partial y^c}{\partial A^{k}_{ij}}\) は自動的に計算できる（逆伝播により）
   - 勾配は「現在の入力に対する感度」を表すため、学習済みパラメータの構造に依存しない
   - 空間平均により、位置依存の重みを「チャネルごとの重要性」に集約できる

**数式的な説明**:

全結合層がある場合、クラススコアは：
\[
y^c = \sum_{k,i,j} w_{k,i,j}^{c} A^{k}_{ij} + b^{c} + \text{(他の層の寄与)}.
\]

勾配は：
\[
\frac{\partial y^c}{\partial A^{k}_{ij}} = w_{k,i,j}^{c} + \text{(他の層を通じた間接的な寄与)}.
\]

これを空間平均すると：
\[
\alpha_k^{c} = \frac{1}{Z} \sum_{i,j} \frac{\partial y^c}{\partial A^{k}_{ij}} = \frac{1}{Z} \sum_{i,j} w_{k,i,j}^{c} + \text{(間接的寄与の平均)}.
\]

**重要な点**: 
- 全結合層だけの場合、\(\alpha_k^{c} = \frac{1}{Z} \sum_{i,j} w_{k,i,j}^{c}\) となり、これは「チャネル \(k\) の全位置での重みの平均」を表す
- これにより、位置依存の重み \(w_{k,i,j}^{c}\) を「チャネルごとの平均的重要性」\(\alpha_k^{c}\) に集約できる
- この \(\alpha_k^{c}\) を使って、CAMと同様に特徴マップを重み付け合成できる

**GAP + 線形分類の場合の一致**:

もしモデルがGAP + 線形分類層なら：
\[
y^c = \sum_k w_k^{c} F_k + b^{c} = \frac{1}{Z} \sum_k w_k^{c} \sum_{i,j} A^{k}_{ij} + b^{c}.
\]

この場合、勾配は：
\[
\frac{\partial y^c}{\partial A^{k}_{ij}} = \frac{w_k^{c}}{Z}.
\]

空間平均すると：
\[
\alpha_k^{c} = \frac{1}{Z} \sum_{i,j} \frac{w_k^{c}}{Z} = \frac{w_k^{c}}{Z}.
\]

つまり、**GAP + 線形分類の場合、Grad-CAMの重み \(\alpha_k^{c}\) はCAMの重み \(w_k^{c}\) と比例関係**にある。これが「Grad-CAMはCAMの一般化」と言われる理由である。

**まとめ**: 
- **CAM**: アーキテクチャ変更（GAP）により「チャネルごとに1つの重み」という構造を強制
- **Grad-CAM**: 勾配の空間平均により、任意のアーキテクチャで「チャネルごとの重要性」を自動的に計算
- **結果**: アーキテクチャ変更不要で、既存モデルにそのまま適用可能

---

### 3. 実装ノート（重要ポイント）
- **層の選択**: **最終畳み込み層**を推奨（高次抽象＋空間分解能のバランス）。
  - **なぜ最終畳み込み層か**:
    - より浅い層（初期畳み込み層）: 低次特徴（エッジ、テクスチャ、色など）を捉える。クラス判別には不十分。
    - **最終畳み込み層**: 高次抽象的特徴（物体のパーツ、形状など）を捉え、かつ空間情報（位置）がまだ保持されている。クラス判別に最適。
    - より深い層（全結合層以降）: 空間情報が失われているため、局在マップを生成できない。
  - 複数の畳み込み層がある場合、通常は最後の畳み込み層（全結合層の直前）を使用する。
- **ターゲット**: ロジット（前ソフトマックス）に対する勾配を計算。
- **正規化**: 可視化時に \(L^{c}_{\text{Grad-CAM}}\) をmin-max正規化しカラーマップ重畳。
- **多タスク/マルチモーダル**: 出力タスク（例: キャプションの単語ロジット、VQAの回答ロジット）に応じて \(y^{c}\) を選択すれば同様に適用可。

---

### 4. 「キモ」と重要性：本論文の核と影響
- **キモ**: 「クラス勾配の空間平均＝チャネル重み」で特徴マップを線形合成し、ReLUで正の寄与に限定するだけの簡潔な式で、広範なCNNにクラス判別的局在を実現。
- **重要性/影響**: CAMの制約を取り払い、多種タスクへ拡張。失敗モード解析・バイアス検出・対人評価で有用性を示し、以降のGrad-CAM++/Score-CAM等の系譜を牽引。

---

### 5. まとめ（要点）
- 重み：\(\alpha_k^{c} = \tfrac{1}{Z}\sum_{i,j} \partial y^{c}/\partial A^{k}_{ij}\)。
- マップ：\(L^{c}_{\text{Grad-CAM}} = \operatorname{ReLU}(\sum_k \alpha_k^{c} A^{k})\)。
- 高解像度化：Guided BPと要素積でGuided Grad-CAM。
- 再学習不要・モデル非依存（CNN最終畳み込み層の勾配が取れれば適用可能）。

参考: [arXiv:1610.02391](https://arxiv.org/abs/1610.02391)
