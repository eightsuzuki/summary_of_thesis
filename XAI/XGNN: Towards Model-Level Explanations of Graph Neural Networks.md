# XGNN: Towards Model-Level Explanations of Graph Neural Networks

**著者**: Hao Yuan (Texas A&M University), Jiliang Tang (Michigan State University), Xia Hu (Rice University), Shuiwang Ji (Texas A&M University)  
**arXiv**: [arXiv:2006.02587](https://arxiv.org/abs/2006.02587)  
**発表年**: 2020年6月

---

### 概要

この論文は、**グラフニューラルネットワーク（GNN）のモデルレベルの説明**を提供する新しい手法**XGNN**を提案した研究です。GNNは隣接ノード情報を集約・結合してノード特徴を学習し、多くのグラフタスクで優れた性能を発揮していますが、その多くはブラックボックスとして扱われ、人間が理解できる説明が不足しています。本論文では、**グラフ生成器を訓練することで、特定の予測を最大化するグラフパターンを生成**し、GNNがどのようなグラフ構造に注目しているかを高レベルで理解できるようにしました。グラフ生成を強化学習タスクとして定式化し、ポリシー勾配法を用いて訓練することで、GNNの動作を説明可能なグラフパターンとして可視化します。

---

### 論文の核心：モデルレベルの説明の必要性

#### 1. 研究の背景と動機

GNNは、ソーシャルネットワーク、分子構造、知識グラフなど、様々なグラフデータに対して優れた性能を示しています。しかし、以下の問題が存在します：

- **ブラックボックス性**: GNNの内部動作が理解しにくく、なぜ特定の予測が行われたのかが不明
- **説明の欠如**: 個別の予測に対する説明（インスタンスレベルの説明）は存在するが、モデル全体がどのようなパターンを学習しているか（モデルレベルの説明）が不足
- **信頼性の問題**: 医療や金融などの重要な応用分野では、モデルの説明可能性が不可欠

#### 2. インスタンスレベル vs モデルレベルの説明

従来の説明手法は主に**インスタンスレベル**の説明に焦点を当てていました：

- **インスタンスレベルの説明**: 特定の入力グラフに対して、どのノードやエッジが予測に重要かを説明
- **モデルレベルの説明**: モデル全体がどのようなグラフパターンを学習しているかを説明

XGNNは、後者の**モデルレベルの説明**を提供することで、GNNの高レベルな理解を可能にします。

---

### XGNNのアプローチ

#### 1. 基本的なアイデア

XGNNの核心的なアイデアは、**特定の予測を最大化するグラフパターンを生成するグラフ生成器を訓練する**ことです。

- **目標**: 学習済みGNNモデルが特定のクラス（例：毒性のある分子）を予測する際に、どのようなグラフ構造が重要かを理解する
- **方法**: 強化学習を用いて、そのクラスの予測スコアを最大化するグラフを生成する
- **結果**: 生成されたグラフパターンが、GNNが学習した重要な構造的特徴を反映する

#### 2. 強化学習によるグラフ生成

グラフ生成を強化学習の枠組みで定式化します：

##### 状態（State）
- 現在構築中のグラフを状態として表現
- 各ステップで、グラフの現在の状態をエンコード

##### 行動（Action）
- 各ステップで、グラフ生成器は新しいエッジを追加する行動を選択
- エッジの追加先（どのノード間にエッジを追加するか）を決定

##### 報酬（Reward）
- 生成されたグラフを学習済みGNNに入力し、目標クラスの予測スコアを報酬として使用
- 予測スコアが高いほど、より良い報酬が得られる

##### ポリシー（Policy）
- グラフ生成器は、現在のグラフ状態から次のエッジを追加する行動を選択するポリシーを学習
- ポリシー勾配法（Policy Gradient）を用いて訓練

#### 3. グラフ生成器のアーキテクチャ

グラフ生成器は、以下のコンポーネントで構成されます：

- **グラフエンコーダ**: 現在のグラフをベクトル表現にエンコード
- **エッジ予測器**: 次のエッジを追加する位置を予測
- **ノード特徴予測器**: 新しく追加されるノードの特徴を予測（必要に応じて）

#### 4. グラフの妥当性を保証する制約

生成されるグラフが有効であることを保証するため、以下のグラフルールを組み込みます：

- **接続性**: グラフが適切に接続されていることを保証
- **サイクル制約**: 特定のタスクではサイクルを許可/禁止
- **ノード数制限**: グラフのサイズを制限
- **エッジタイプ制約**: 有向グラフや異種グラフの場合の制約

---

### 技術的な詳細

#### 1. ポリシー勾配法の適用

グラフ生成器の訓練には、REINFORCEアルゴリズムなどのポリシー勾配法が使用されます。

**目的関数**:
$$\max_{\theta} \mathbb{E}_{G \sim p_{\theta}(G)} [R(G)]$$

ここで：
- $p_{\theta}(G)$: パラメータ$\theta$を持つグラフ生成器がグラフ$G$を生成する確率
- $R(G)$: グラフ$G$に対する報酬（学習済みGNNの予測スコア）

**勾配**:
$$\nabla_{\theta} J(\theta) = \mathbb{E}_{G \sim p_{\theta}(G)} [R(G) \nabla_{\theta} \log p_{\theta}(G)]$$

#### 2. 報酬関数の設計

報酬関数は、生成されたグラフが目標クラスに対してどの程度高い予測スコアを持つかを測定します：

$$R(G) = f_{\text{GNN}}(G, y_{\text{target}})$$

ここで：
- $f_{\text{GNN}}$: 学習済みGNNモデル
- $y_{\text{target}}$: 説明したい目標クラス

#### 3. グラフ生成のプロセス

グラフ生成は、以下のステップで行われます：

1. **初期化**: 空のグラフまたは初期ノードから開始
2. **反復的エッジ追加**: 
   - 現在のグラフ状態をエンコード
   - ポリシーに基づいて次のエッジを選択
   - エッジを追加してグラフを更新
3. **終了条件**: 最大エッジ数に達するか、終了アクションが選択されるまで繰り返し
4. **報酬計算**: 完成したグラフをGNNに入力し、報酬を計算
5. **ポリシー更新**: 報酬に基づいてポリシーを更新

---

### 実験と評価

#### 1. 実験設定

論文では、以下のデータセットで実験が行われました：

- **合成データセット**: 制御された環境でXGNNの有効性を検証
- **実世界データセット**: 分子データセット（毒性予測など）で実用性を検証

#### 2. 評価指標

XGNNの説明能力を評価するために、以下の指標が使用されました：

- **生成グラフの予測スコア**: 生成されたグラフが目標クラスに対してどの程度高いスコアを持つか
- **グラフの多様性**: 生成されるグラフパターンの多様性
- **人間による評価**: 生成されたグラフパターンが意味的に理解可能か

#### 3. 主要な結果

実験結果から、以下のことが明らかになりました：

- **説明可能性**: XGNNは、GNNが学習した重要なグラフパターンを可視化できる
- **検証可能性**: 生成されたグラフパターンを用いて、GNNの動作を検証できる
- **改善の指針**: 生成されたグラフパターンから、GNNの改善方法に関する洞察が得られる

---

### 論文の意義と貢献

#### 1. モデルレベルの説明の提供

XGNNは、GNNの**モデルレベルの説明**を提供する初めての手法の一つです。これにより、以下のことが可能になりました：

- **高レベルな理解**: GNNがどのようなグラフパターンを学習しているかを理解できる
- **モデルの検証**: 生成されたパターンが期待されるものと一致するかを検証できる
- **モデルの改善**: 生成されたパターンから、モデルの改善方法を発見できる

#### 2. 強化学習の応用

グラフ生成を強化学習の枠組みで定式化することで、以下の利点があります：

- **柔軟性**: 様々なグラフ構造を生成できる
- **最適化**: 目標を直接最適化できる
- **拡張性**: 様々な制約や報酬関数を組み込める

#### 3. 実用的な応用

XGNNは、以下のような実用的な応用が可能です：

- **分子設計**: 毒性や薬効を持つ分子の構造パターンを理解
- **ソーシャルネットワーク分析**: コミュニティ検出や影響力分析の理解
- **知識グラフ**: 知識グラフの重要なパターンを発見

---

### 限界と今後の課題

#### 1. 計算コスト

強化学習によるグラフ生成は、計算コストが高い場合があります：

- **サンプリング効率**: 多くのグラフサンプルが必要
- **収束速度**: ポリシーの収束に時間がかかる場合がある

#### 2. グラフの複雑さ

生成されるグラフの複雑さに関する制約：

- **グラフサイズ**: 大きなグラフの生成は困難
- **構造の多様性**: 生成されるグラフの多様性を保証する必要がある

#### 3. 評価の難しさ

モデルレベルの説明の評価は、インスタンスレベルの説明よりも困難です：

- **定量的評価**: 説明の質を定量的に評価する方法が限られている
- **人間による評価**: 主観的な評価に依存する部分がある

---

### 実践的な示唆

#### 1. GNNの理解と検証

XGNNを使用することで、以下のことが可能になります：

- **モデルの動作理解**: GNNがどのようなパターンを学習しているかを理解
- **バイアスの発見**: モデルが学習したバイアスや不適切なパターンを発見
- **モデルの検証**: 生成されたパターンが期待されるものと一致するかを検証

#### 2. モデルの改善

生成されたグラフパターンから、以下のような改善方法を発見できます：

- **データの不足**: 重要なパターンがデータに不足している場合の特定
- **アーキテクチャの改善**: より良いグラフ構造を学習できるアーキテクチャの設計
- **正則化**: 不適切なパターンを抑制する正則化手法の設計

---

### まとめ

XGNNは、GNNのモデルレベルの説明を提供する画期的な手法です。強化学習を用いてグラフ生成器を訓練することで、GNNが学習した重要なグラフパターンを可視化し、モデルの高レベルな理解を可能にします。この手法は、GNNの説明可能性を大幅に向上させ、医療、化学、ソーシャルネットワーク分析などの重要な応用分野での信頼性を高めることが期待されます。

XGNNは、GNNのブラックボックス性を解消し、モデルの動作を理解・検証・改善するための強力なツールを提供します。今後の研究では、計算効率の向上、より複雑なグラフの生成、評価方法の改善などが重要な課題となるでしょう。
