# CAM: Learning Deep Features for Discriminative Localization

**著者**: Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba  
**公開**: arXiv 2015  
**DOI**: 10.48550/arXiv.1512.04150  
**リンク**: [arXiv:1512.04150](https://arxiv.org/abs/1512.04150)

本論文は、最終畳み込み層の後に**Global Average Pooling (GAP)** を導入することで、**画像レベルのラベルのみ**で学習したCNNから、クラス判別的な**Class Activation Map (CAM)** を得て粗い物体局在を実現できることを示します。GAPは単なる正則化に留まらず、ローカライズ可能な表現を構築します。

---

### 1. 新規性：この論文の貢献
- **GAPでローカライズ可能な表現**: 全結合層の代わりにGAPを用いると、クラス判別に効いたチャネルの空間分布をそのまま可視化できる。
- **弱教師あり局在**: 画像ラベルのみの学習で、ILSVRC 2014 の物体局在（Top-5 37.1%）に迫る精度を達成。
- **シンプルな重み付き合成**: 学習済みのクラス線形重みを最終特徴マップに適用するだけでCAMが得られる。

---

### 2. 理論/手法の核心：数式できっちり定式化

#### 記法
- **最終畳み込み層**のチャネル別特徴マップ \(A^{k} \in \mathbb{R}^{H\times W}\)（\(k=1,\dots,K\)）。
- Global Average Pooling によりチャネル要約 \(F_k\):
\[
F_k \,=\, \frac{1}{Z} \sum_{i=1}^{H} \sum_{j=1}^{W} A^{k}_{ij},\quad Z=H\times W.
\]
- クラス \(c\) の線形分類器（バイアス \(b^c\) を含む）:
\[
 y^{c} \,=\, \sum_{k=1}^{K} w_k^{c} \, F_k \, + \, b^{c}.
\]

**重要**: CAMは**最終畳み込み層**のチャネルのみを使用します。中間層のチャネルは使用しません。
- **理由**: 最終畳み込み層は、クラス判別に必要な高次抽象的特徴を保持しつつ、空間情報（位置情報）がまだ残っている唯一の層である。
- より浅い層は低次特徴を捉えており、より深い層（全結合層以降）は空間情報が失われている。

#### Global Average Pooling (GAP) とは
**Global Average Pooling (GAP)** は、空間次元（高さ \(H\) × 幅 \(W\)）全体を平均化して、各チャネル \(k\) を1つのスカラー値 \(F_k\) に要約する操作です。

**定義**:
- 入力: 特徴マップ \(A^{k} \in \mathbb{R}^{H\times W}\)（各チャネル \(k=1,\dots,K\)）
- 出力: スカラー値 \(F_k = \frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} A^{k}_{ij}\)

**他のPooling手法との比較**:
- **Global Average Pooling (GAP)**: 空間全体の平均値を取る。全位置を等しく考慮し、空間情報を保持しつつ要約。
- **Global Max Pooling (GMP)**: 空間全体の最大値を取る。最も強い活性化のみに注目し、局所性が強すぎる場合がある。
- **全結合層（FC層）**: 空間位置ごとに異なる重みを持つため、空間情報が失われ、CAMの生成が困難。

**CAMにおけるGAPの重要性**:
1. **空間情報の保持**: GAPは平均化により空間情報を「集約」するが「破棄」しない。そのため、後で重み \(w_k^c\) を空間次元に戻すことで、どの位置がクラス判別に寄与したかを復元できる。
2. **線形性の維持**: GAPは線形操作（平均）のため、クラススコア \(y^c = \sum_k w_k^c F_k + b^c\) と特徴マップ \(A^k\) の関係が単純になり、CAM \(M^c(i,j) = \sum_k w_k^c A^k_{ij}\) が直接計算できる。
3. **パラメータ削減**: 全結合層の代わりにGAPを使うことで、パラメータ数を大幅に削減し、過学習を抑制（正則化効果）。

**従来のCNNアーキテクチャとの違い**:
- **従来**: Conv層 → FC層 → Softmax（空間情報が失われる）
- **CAM**: Conv層 → GAP → 線形分類層 → Softmax（空間情報を保持）

#### Class Activation Map (CAM)
クラス \(c\) に対する**クラス活性化マップ**は、学習済み重みで特徴マップを線形合成：
\[
 M^{c}(i,j) \,=\, \sum_{k=1}^{K} w_k^{c} \, A^{k}_{ij}.
\]
- 直感: GAP で平均値 \(F_k\) を取り、線形分類重み \(w_k^c\) でクラス決定。GAPの“逆操作”として \(w_k^c\) を空間次元に戻して合成すると、どの位置がクラスに寄与したかが得られる。
- 実装: \(M^{c}\) を入力画像解像度へ双一次補間し、min–max 正規化後に可視化。閾値化や最大連結成分抽出でBBox/マスクを得る。

#### なぜアーキテクチャ変更（GAP）が必要なのか

**問題**: 従来のCNNアーキテクチャ（Conv層 → 全結合層 → Softmax）では、CAMを生成できない。

**理由1: 全結合層では空間位置ごとに異なる重みを持つ**

従来のアーキテクチャでは、クラススコアは以下のように計算される：
\[
y^c = \sum_{k=1}^{K} \sum_{i=1}^{H} \sum_{j=1}^{W} w_{k,i,j}^{c} \, A^{k}_{ij} + b^{c}.
\]
ここで、\(w_{k,i,j}^{c}\) は**チャネル \(k\) の位置 \((i,j)\) ごとに異なる重み**である。

この場合、CAMを生成しようとしても：
- 各位置 \((i,j)\) に対して異なる重み \(w_{k,i,j}^{c}\) が存在する
- どの重みを空間次元に「戻す」べきかが不明確
- 単純に \(M^c(i,j) = \sum_k w_{k,i,j}^{c} A^k_{ij}\) とすると、これは元のクラススコア計算そのもので、可視化として意味がない

**理由2: GAPを使うとチャネルごとに1つの重みで表現できる**

GAPを導入すると、クラススコアは以下のように簡潔になる：
\[
y^c = \sum_{k=1}^{K} w_k^{c} \, F_k + b^{c} = \sum_{k=1}^{K} w_k^{c} \, \left( \frac{1}{Z} \sum_{i=1}^{H} \sum_{j=1}^{W} A^{k}_{ij} \right) + b^{c}.
\]

これを展開すると：
\[
y^c = \frac{1}{Z} \sum_{k=1}^{K} \sum_{i=1}^{H} \sum_{j=1}^{W} w_k^{c} \, A^{k}_{ij} + b^{c}.
\]

**重要な点**: ここでは、**チャネル \(k\) ごとに1つの重み \(w_k^{c}\) のみ**が存在し、空間位置 \((i,j)\) には依存しない。

**理由3: GAPにより「逆操作」が可能になる**

GAPを使った場合、クラススコア \(y^c\) と特徴マップ \(A^k\) の関係が線形で単純になるため、以下のように「逆操作」が可能：
\[
M^{c}(i,j) = \sum_{k=1}^{K} w_k^{c} \, A^{k}_{ij}.
\]

この \(M^{c}(i,j)\) を空間全体で平均すると：
\[
\frac{1}{Z} \sum_{i,j} M^{c}(i,j) = \frac{1}{Z} \sum_{i,j} \sum_{k} w_k^{c} \, A^{k}_{ij} = \sum_{k} w_k^{c} \, F_k = y^c - b^{c}.
\]

つまり、**CAM \(M^{c}(i,j)\) の空間平均がクラススコア（バイアス除く）と一致**する。これにより、\(M^{c}(i,j)\) は「位置 \((i,j)\) がクラス \(c\) のスコアにどれだけ寄与したか」を表す意味のある可視化となる。

**全結合層ではこの関係が成り立たない理由**:
- 全結合層では \(w_{k,i,j}^{c}\) が位置依存のため、単純な「逆操作」ができない
- 各位置で異なる重みが使われているため、どの重みを「戻す」べきかが不明確
- GAPのように「チャネルごとに1つの重み」という構造がないため、CAMの生成が不可能

**まとめ**: GAPは「チャネルごとに1つの重み」という構造を強制することで、学習済み重みを空間次元に戻してCAMを生成できるようにする。これがアーキテクチャ変更が必要な根本的な理由である。

#### CAMとGrad-CAMの違い（参考）

**主な違い**:
- **CAM**: 
  - アーキテクチャ変更（GAP＋線形層）が**必須**（上記の理由により）
  - 学習済みの線形分類層の重み \(w_k^c\) を直接使用して特徴マップを合成
  - 再学習が必要
  - 適用範囲が限定的（GAP + 線形分類層を持つモデルのみ）

- **Grad-CAM**: 
  - 既存モデルに**そのまま適用可能**（アーキテクチャ変更不要）
  - 勾配の空間平均 \(\alpha_k^c = \frac{1}{Z}\sum_{i,j} \frac{\partial y^c}{\partial A^k_{ij}}\) を重みとして計算
  - 再学習不要
  - 任意のCNNアーキテクチャに適用可能（ResNet、VGG、Inceptionなど）
  - \(\operatorname{ReLU}\) を通して正の寄与のみを強調

**数式の違い**:
- **CAM**: \(M^c(i,j) = \sum_k w_k^c A^k_{ij}\)
- **Grad-CAM**: \(L^c_{\text{Grad-CAM}} = \operatorname{ReLU}(\sum_k \alpha_k^c A^k)\)

**関係性**: Grad-CAMはCAMの一般化。GAP + 線形分類の場合、勾配 \(\alpha_k^c\) は学習済み重み \(w_k^c\) と一致（または比例）するため、Grad-CAMは任意のCNNにCAMの考え方を拡張した手法と言える。

詳細は [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization.md](./Grad-CAM:%20Visual%20Explanations%20from%20Deep%20Networks%20via%20Gradient-based%20Localization.md) のセクション2.3を参照。

---

### 3. 実装ノート
- **設計**: 全結合層を廃し、GAP→線形分類（Softmax前）にする。GMP（Global Max Pooling）は局所性が強すぎる場合があるため論文ではGAPを推奨。
- **正規化**: CAMはチャネルスケールに敏感。学習時の正規化（BN等）や可視化時のスケール処理が安定化に寄与。
- **後処理**: 閾値はデータセットやクラス依存で最適化。弱教師あり局在の評価（Top-k localization）には最大成分抽出が有効。

---

### 4. 「キモ」と重要性
- **キモ**: GAPにより「クラス判別に効いたチャネルの空間的痕跡」をそのまま可視化でき、学習済み線形重み \(w_k^c\) だけでCAMが構成できる極めて簡潔な枠組み。
- **重要性**: 弱教師あり局在の実用的ベースラインを確立し、以後のGrad-CAM系列や他のローカライゼーション手法の基盤となった。

---

### 5. まとめ（要点）
- GAP: \(F_k = \tfrac{1}{Z}\sum_{i,j} A^k_{ij}\)。
- クラススコア: \(y^c = \sum_k w_k^c F_k + b^c\)。
- CAM: \(M^c(i,j) = \sum_k w_k^c A^k_{ij}\)。
- 弱教師あり局在に有効で、アーキテクチャはシンプル。

参考: [arXiv:1512.04150](https://arxiv.org/abs/1512.04150)
