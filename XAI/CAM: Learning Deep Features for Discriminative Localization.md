# CAM: Learning Deep Features for Discriminative Localization

**著者**: Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba  
**公開**: arXiv 2015  
**DOI**: 10.48550/arXiv.1512.04150  
**リンク**: [arXiv:1512.04150](https://arxiv.org/abs/1512.04150)

本論文は、最終畳み込み層の後に**Global Average Pooling (GAP)** を導入することで、**画像レベルのラベルのみ**で学習したCNNから、クラス判別的な**Class Activation Map (CAM)** を得て粗い物体局在を実現できることを示します。GAPは単なる正則化に留まらず、ローカライズ可能な表現を構築します。

---

### 1. 新規性：この論文の貢献
- **GAPでローカライズ可能な表現**: 全結合層の代わりにGAPを用いると、クラス判別に効いたチャネルの空間分布をそのまま可視化できる。
- **弱教師あり局在**: 画像ラベルのみの学習で、ILSVRC 2014 の物体局在（Top-5 37.1%）に迫る精度を達成。
- **シンプルな重み付き合成**: 学習済みのクラス線形重みを最終特徴マップに適用するだけでCAMが得られる。

---

### 2. 理論/手法の核心：数式できっちり定式化

#### 記法
- 最終畳み込み層のチャネル別特徴マップ \(A^{k} \in \mathbb{R}^{H\times W}\)（\(k=1,\dots,K\)）。
- Global Average Pooling によりチャネル要約 \(F_k\):
\[
F_k \,=\, \frac{1}{Z} \sum_{i=1}^{H} \sum_{j=1}^{W} A^{k}_{ij},\quad Z=H\times W.
\]
- クラス \(c\) の線形分類器（バイアス \(b^c\) を含む）:
\[
 y^{c} \,=\, \sum_{k=1}^{K} w_k^{c} \, F_k \, + \, b^{c}.
\]

#### Class Activation Map (CAM)
クラス \(c\) に対する**クラス活性化マップ**は、学習済み重みで特徴マップを線形合成：
\[
 M^{c}(i,j) \,=\, \sum_{k=1}^{K} w_k^{c} \, A^{k}_{ij}.
\]
- 直感: GAP で平均値 \(F_k\) を取り、線形分類重み \(w_k^c\) でクラス決定。GAPの“逆操作”として \(w_k^c\) を空間次元に戻して合成すると、どの位置がクラスに寄与したかが得られる。
- 実装: \(M^{c}\) を入力画像解像度へ双一次補間し、min–max 正規化後に可視化。閾値化や最大連結成分抽出でBBox/マスクを得る。

#### CAMとGrad-CAMの違い（参考）
- CAM: アーキテクチャ変更（GAP＋線形層）が必要。重み \(w_k^c\) で合成。
- Grad-CAM: 既存モデルに適用可。勾配の空間平均 \(\alpha_k^c\) を重みとして合成し、\(\operatorname{ReLU}\) を通して可視化。

---

### 3. 実装ノート
- **設計**: 全結合層を廃し、GAP→線形分類（Softmax前）にする。GMP（Global Max Pooling）は局所性が強すぎる場合があるため論文ではGAPを推奨。
- **正規化**: CAMはチャネルスケールに敏感。学習時の正規化（BN等）や可視化時のスケール処理が安定化に寄与。
- **後処理**: 閾値はデータセットやクラス依存で最適化。弱教師あり局在の評価（Top-k localization）には最大成分抽出が有効。

---

### 4. 「キモ」と重要性
- **キモ**: GAPにより「クラス判別に効いたチャネルの空間的痕跡」をそのまま可視化でき、学習済み線形重み \(w_k^c\) だけでCAMが構成できる極めて簡潔な枠組み。
- **重要性**: 弱教師あり局在の実用的ベースラインを確立し、以後のGrad-CAM系列や他のローカライゼーション手法の基盤となった。

---

### 5. まとめ（要点）
- GAP: \(F_k = \tfrac{1}{Z}\sum_{i,j} A^k_{ij}\)。
- クラススコア: \(y^c = \sum_k w_k^c F_k + b^c\)。
- CAM: \(M^c(i,j) = \sum_k w_k^c A^k_{ij}\)。
- 弱教師あり局在に有効で、アーキテクチャはシンプル。

参考: [arXiv:1512.04150](https://arxiv.org/abs/1512.04150)
