# LORE: Local Rule-Based Explanations of Black Box Decision Systems

**著者**: Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Dino Pedreschi, Franco Turini, Fosca Giannotti  
**公開**: arXiv 2018（2018-05-28）  
**DOI**: 10.48550/arXiv.1805.10820  
**リンク**: [arXiv:1805.10820](https://arxiv.org/abs/1805.10820)

本論文は、ブラックボックス決定システムの**個別インスタンスに対する結果説明（outcome explanation）**を提供する **LORE (Local Rule-Based Explanations)** を提案します。LOREは、遺伝的アルゴリズムで生成した合成近傍上で局所的な解釈可能な予測器を学習し、その論理から**決定ルール**（なぜその決定が下されたか）と**反事実ルール**（どの特徴を変更すれば異なる結果になるか）を導出します。モデル非依存（agnostic）であり、説明の忠実性と解釈可能性の両立を目指します。

---

### 1. 新規性：この論文の貢献と既存研究との差分

- **局所ルールベース説明**: 決定ルールと反事実ルールの両方を提供し、予測の理由と変更可能性を同時に説明。
- **遺伝的アルゴリズムによる近傍生成**: ランダムサンプリングではなく、遺伝的アルゴリズムでブラックボックスの挙動をよく反映する局所近傍を生成。
- **解釈可能な局所予測器**: 決定木などの解釈可能モデルを局所的に学習し、その論理からルールを抽出。
- **モデル非依存**: 任意のブラックボックス分類器に適用可能（予測クエリのみ必要）。

---

### 2. 理論/手法の核心：数式できっちり定式化

#### 記法と前提
- ブラックボックス分類器 \(f: \mathcal{X} \to \mathcal{Y}\)（\(\mathcal{X}\): 特徴空間、\(\mathcal{Y}\): クラス集合）。
- 説明対象のインスタンス \(x \in \mathcal{X}\)。ブラックボックスの予測 \(y = f(x)\)。
- 局所近傍 \(\mathcal{N}(x)\): \(x\) の周辺で生成されたサンプル集合。
- 解釈可能な局所予測器 \(g\)（例: 決定木、ルールリスト）。

#### 2.1 LOREの2段階アプローチ

**ステップ1: 局所近傍の生成（遺伝的アルゴリズム）**
- 目的: \(x\) の近傍で、ブラックボックスの挙動をよく反映する多様なサンプルを生成。
- 遺伝的アルゴリズム（GA）の設計:
  - **個体**: \(x\) を中心とした特徴ベクトル \(z \in \mathcal{X}\)。
  - **適応度関数**: ブラックボックス \(f\) の予測の多様性と局所性を考慮（例: \(f(z)\) の分布の多様性、\(x\) からの距離ペナルティ）。
  - **操作**: 交叉（crossover）、突然変異（mutation）、選択（selection）。
- 生成された近傍 \(\mathcal{N}(x) = \{z_1, z_2, ..., z_N\}\) と対応するラベル \(\{f(z_1), f(z_2), ..., f(z_N)\}\)。

**ステップ2: 局所解釈可能予測器の学習**
- 近傍 \(\mathcal{N}(x)\) とラベルから、解釈可能な分類器 \(g\) を学習:
\[
g = \arg\min_{g' \in \mathcal{G}} \mathcal{L}\bigl(\{f(z_i)\}, \{g'(z_i)\}\bigr) + \lambda \Omega(g').
\]
ここで、\(\mathcal{G}\) は解釈可能モデル族（決定木、ルールリストなど）、\(\mathcal{L}\) は損失関数、\(\Omega\) は複雑度ペナルティ。

**ステップ3: ルール抽出**
- **決定ルール（Decision Rule）**: \(g\) が \(x\) を分類する際に使用した条件（If-Thenルール）。例: "If \(x_1 > 0.5\) AND \(x_2 < 0.3\) Then \(y = 1\)"。
- **反事実ルール（Counterfactual Rules）**: \(x\) の特徴を変更した場合に異なる予測になる条件。\(g\) の論理から、最小限の変更で予測が変わるパスを探索。

#### 2.2 反事実ルールの生成
- \(x\) が \(g\) で予測クラス \(y\) に分類される条件を \(R\) とする。
- 異なるクラス \(y' \ne y\) に分類される条件 \(R'\) を探索。
- 最小変更距離（例: 特徴変更数、L1/L2距離）で \(R'\) に到達する反事実インスタンス \(x'\) を生成。
- 反事実ルール: "If \(x'_1 = v_1\) AND \(x'_2 = v_2\) ... Then \(y'\)"（\(x\) との差分を強調）。

---

### 3. 実装ノート

- **解釈可能モデル**: 決定木（CART、C4.5など）が一般的。ルールリストや線形モデルも可能。
- **遺伝的アルゴリズムのパラメータ**: 個体数、世代数、交叉率、突然変異率、適応度関数の設計。
- **近傍サイズ**: \(N\) は数百〜数千程度。局所性と多様性のバランス。
- **反事実探索**: 貪欲法、ビームサーチ、または最適化ベース（例: 勾配降下で特徴変更を最小化）。

---

### 3.5. 適用例とデータタイプ

**適用可能なデータタイプ**:
- **表形式データ**: 金融リスク評価、医療診断、顧客分析など。各特徴量をそのまま使用。
- **混合データ**: 連続値・カテゴリ値の組み合わせにも対応。

**使用例**:
- **金融**: 「なぜこの融資申請が"拒否"されたか」→ 決定ルール（例: "年収 < 50,000 AND 信用スコア < 600"）と反事実ルール（例: "年収を 60,000 以上にすれば承認される可能性が高い"）を提示。
- **医療**: 「なぜこの患者が"高リスク"と判定されたか」→ 決定ルールと、リスクを下げるための反事実条件を提示。

---

### 3.6. 他の手法との違い

**LORE vs LIME**:
- **LORE**: 遺伝的アルゴリズムで近傍生成、決定ルールと反事実ルールの両方を提供、決定木ベースの解釈。
- **LIME**: ランダムサンプリングで近傍生成、線形モデルで特徴重要度を提供、連続的な寄与度。
- **補完的**: LOREは「If-Thenルール」と「変更可能性」を、LIMEは「特徴の寄与度」を説明。

**LORE vs Anchors**:
- **LORE**: 遺伝的アルゴリズムで近傍生成、決定ルールと反事実ルールの両方を提供。
- **Anchors**: 高精度保証つきの局所十分条件（Anchor）を提供、統計的保証あり。
- **違い**: LOREは反事実も提供し、Anchorsは精度保証に重点。

**LORE vs SHAP**:
- **LORE**: ルールベース、局所的な決定木から抽出、反事実を含む。
- **SHAP**: 特徴重要度の加法的分解、Shapley値による理論的保証。
- **説明形式**: LOREは「ルール」、SHAPは「数値的な寄与度」。

---

### 4. 「キモ」と重要性：本論文の核と影響

- **キモ**: 「遺伝的アルゴリズムによる局所近傍生成 → 解釈可能モデル学習 → ルール抽出」という3段階アプローチで、決定ルールと反事実ルールを同時に提供。ブラックボックスの個別予測を「なぜ」と「どうすれば変わるか」の両面から説明。
- **重要性/影響**: 反事実説明（counterfactual explanations）の重要性を強調し、XAIにおける「変更可能性」の説明を普及させた。実務では、ユーザが「どうすれば結果が変わるか」を知りたい場面で有用。

---

### 5. まとめ（要点）

- **3段階アプローチ**: (1) 遺伝的アルゴリズムで局所近傍生成、(2) 解釈可能モデル（決定木など）を学習、(3) 決定ルールと反事実ルールを抽出。
- **決定ルール**: ブラックボックスが特定の予測を下した理由をIf-Then形式で説明。
- **反事実ルール**: 特徴を変更した場合に異なる予測になる条件を提示。
- **モデル非依存**: 任意のブラックボックス分類器に適用可能（予測クエリのみ必要）。
- **遺伝的アルゴリズム**: ランダムサンプリングではなく、適応度に基づいて局所近傍を生成。

参考: [arXiv:1805.10820](https://arxiv.org/abs/1805.10820)
