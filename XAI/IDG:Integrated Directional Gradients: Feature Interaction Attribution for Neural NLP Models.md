# Integrated Directional Gradients: Feature Interaction Attribution for Neural NLP Models
**著者**: Sandipan Sikdar (RWTH Aachen University), 
Parantapa Bhattacharya (University of Virginia) ,
Kieran Heese (University of Virginia)  
**会議**: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)  
**arXiv**: https://aclanthology.org/2021.acl-long.71/ 
**GitHub**: https://github.com/parantapa/integrated-directional-gradients

---

### 1. 新規性：この論文の貢献と既存研究との違い

この論文の最も大きな貢献は、ニューラルネットワークにおける**特徴量グループの重要度（アトリビューション）を評価するための新しい公理的フレームワークと、その公理を満たす手法「Integrated Directional Gradients (IDG)」を提案した点**です。

既存研究との主な違いは以下の通りです。

* **問題設定の厳密な定義**: 従来曖昧だった「特徴量グループのアトリビューション問題」を、協力ゲーム理論の枠組みを用いて形式的に定義しました [cite: 4, 28]。
* **協力ゲーム理論のより深い応用**: 既存の多くの手法は、協力ゲーム理論の「解概念（例: Shapley値）」が満たすべき公理を借用するに留まっていました [cite: 5]。これに対しIDGは、ゲームの前提を定義する**「特性関数(characteristic function)」自体が満たすべき公理（非負性、単調性、超加法性など）**も導入しました [cite: 6, 22]。これにより、特徴量のグループ化がもたらす価値をより直感的にモデル化できます [cite: 7, 23]。
* **公理の充足**: 提案手法IDGが、自身で定めた8つの公理（後述）をすべて満たすことを数学的に証明しました [cite: 8, 106]。特に、既存の多くの手法では保証されていなかった**超加法性**（複数の特徴量グループを統合した価値は、個々の価値の合計以上になる）などを満たします [cite: 58, 138]。
* **評価の信頼性**: 多くの既存手法は、特徴量をマスクする（例: ゼロで置き換える）ことでモデルを評価しますが、これはモデルが学習データで見たことのない分布外（Out-of-Distribution）の入力に対する評価となり、信頼性に欠けるという問題がありました [cite: 134, 135]。IDGは、ベースラインからの経路積分を用いることで、このような分布外の評価を回避します [cite: 136]。

### 2. 理論/手法の核心：IDGの詳細

IDGは、特徴量グループの重要度を「配当（dividend）」という概念を用いて階層的に計算する手法です [cite: 86]。

#### 問題の定式化

まず、この論文は「特徴量グループアトリビューション問題」を以下のように定義します [cite: 41]。

* ニューラルネットワーク関数を $f(x)$ とする。ここで $x \in \mathbb{R}^n$ はn次元の入力ベクトル。
* $A = \{a_1, a_2, ..., a_n\}$ を特徴量の全集合とする [cite: 40]。
* $b \in \mathbb{R}^n$ を、特徴量の寄与がない状態を表すベースラインベクトルとする（例: すべての要素が0のベクトル） [cite: 49]。
* $M \subseteq \mathcal{P}(A)$ を、「意味のある」特徴量部分集合の族（family）とする [cite: 41]。$\mathcal{P}(A)$ はAのべき集合です [cite: 42]。例えば、文の構文解析木における各句が$M$の要素に対応します [cite: 26, 52]。
* この設定の下で、任意の特徴量部分集合 $S \subseteq A$ に対して、その重要度スコア $v(S)$ を割り当てる関数 $v$ を設計することが目的です [cite: 41, 45]。

#### IDGの計算プロセス

IDGは、以下のステップで特徴量グループの価値 $v(S)$ を計算します [cite: 103]。

1.  **方向性ベクトルの定義**:
    ある特徴量グループ $S$ のみが寄与する方向を示すベクトル $z^s$ を定義します [cite: 104]。
    $$
    z_{i}^{s} = \begin{cases} x_{i} - b_{i} & \text{if } a_{i} \in S \\ 0 & \text{otherwise} \end{cases}
    $$
    ここで、$x_i$ は入力、$b_i$ はベースラインのi番目の特徴量の値です [cite: 100]。

2.  **方向性微分の計算**:
    関数 $f(x)$ の、$S$ の方向への変化率（方向性微分）を計算します。
    $$
    \nabla_{S}f(x) = \nabla f(x) \cdot \hat{z}^{s} \quad \text{where} \quad \hat{z}^{s} = \frac{z^{s}}{\|z^{s}\|}
    $$
    $\nabla f(x)$ は $f(x)$ の勾配、$\hat{z}^{s}$ は $z^s$ を正規化した単位ベクトルです [cite: 100]。

3.  **IDGの計算（経路積分）**:
    勾配飽和の問題を避けるため、ベースライン $b$ から入力 $x$ までの直線経路上で方向性微分を積分します。これを $IDG(S)$ と定義します [cite: 98]。
    $$
    IDG(S) = \int_{\alpha=0}^{1} \nabla_{S}f(b+\alpha(x-b)) d\alpha
    $$
    この積分は、実際にはリーマン和で近似されます [cite: 107]。

4.  **配当 (Dividend) の計算**:
    各「意味のある」グループ $S \in M$ が独自に生み出す価値、すなわち「配当」 $d(S)$ を計算します。これは、$|IDG(S)|$ を、全ての意味のあるグループの $|IDG|$ の合計で正規化したものです [cite: 105]。
    $$
    d(S) = \begin{cases} \frac{|IDG(S)|}{Z} & \text{if } S \in M \\ 0 & \text{otherwise} \end{cases}
    $$   
    $$
    Z = \sum_{T \in M} |IDG(T)|
    $$
    これにより、全ての配当の合計が1になります [cite: 105]。

5.  **価値 (Value) の計算**:
    最終的に、あるグループ $S$ の価値 $v(S)$ は、$S$ に含まれるすべての「意味のある」部分集合 $T$ （$S$自身も含む）の配当 $d(T)$ の総和として定義されます [cite: 105]。
    $$
    v(S) = \sum_{T \in \{T | T \subseteq S \land T \in M\}} d(T)
    $$
    この定義により、$v(S)$ は階層的にボトムアップで計算されます [cite: 38, 119]。

### 3. 「キモ」と重要性：この論文の核となるアイデアとその影響

#### この論文の「キモ」（核となるアイデア）

この論文の「キモ」は、以下の2点に集約されます。

1.  **協力ゲーム理論における「特性関数」の公理に着目した点**:
    従来の手法が主に最終的な利得分配（Shapley値など）の公平性に注目していたのに対し、この研究は、その前提となる「協力によってどれだけの価値が生まれるか」を定義する**特性関数 $v(S)$ 自体が満たすべき性質（公理）**に焦点を当てました [cite: 6, 7, 22]。特に、**超加法性**（`Axiom 4: Superadditivity` [cite: 58]）を導入することで、「特徴量が協力すれば、その価値は個々の価値の和以上になるはずだ」という直感を理論に組み込みました [cite: 60]。これが、より信頼性の高い説明性の基盤となっています。

2.  **特徴量グループの相互作用を「方向性勾配の積分」として捉えた点**:
    単一特徴量の重要度を勾配で測るアイデアを、特徴量グループの**相互作用**に拡張しました。グループの相互作用を、そのグループが構成する「方向」へのモデル出力の変化率（方向性微分）として捉え、これをベースラインから入力まで積分（Integrated Gradients）することで、局所的な勾配の問題（飽和など）を克服し、頑健な重要度スコアを算出しています [cite: 95, 98]。

#### 分野への影響と重要性

この研究は、AIの説明可能性（XAI）、特にNLPの分野において以下の点で重要です。

* **より信頼性の高い階層的説明の実現**: IDGは、構文解析木などの階層構造を利用して、単語レベルから句、文全体に至るまでの重要度を計算できます [cite: 26, 38]。これにより、「`not very good`」のような否定辞を含む句が、どのようにして全体のネガティブな感情に寄与したかを、公理に裏付けられた形で可視化できます [cite: 10, 150]。これは、モデルが言語の構成的意味をどう解釈しているかを深く理解する上で非常に強力なツールとなります。
* **説明手法の評価に新たな基準を提示**: 定量的な評価が難しいとされる説明可能性の研究分野において、「どのような公理を満たすべきか」という質的な比較基準を明確に示しました [cite: 126, 127]。Table 1 [cite: 152] で示されているように、既存手法との公理的な比較は、今後の研究が目指すべき方向性を示す上で重要な貢献です。
* **説明可能性に対する攻撃への耐性**: 既存の説明手法の中には、意図的にモデルを騙すような敵対的攻撃に弱いものがあります [cite: 318, 320]。IDGは分布外のデータ評価を避ける設計になっているため、そうした攻撃に対して比較的頑健である可能性が示唆されていますが、これは今後の重要な研究課題とされています [cite: 322, 323]。