# Visualizing and Understanding Convolutional Networks

**著者**: Matthew D. Zeiler, Rob Fergus  
**公開**: arXiv 2013（v3: 2013-11-28）  
**DOI**: 10.48550/arXiv.1311.2901  
**リンク**: [arXiv:1311.2901](https://arxiv.org/abs/1311.2901)

本論文は、大規模ConvNetがなぜうまく動くのかを理解するため、**Deconvolutional Network（DeconvNet）** に基づく可視化技術を導入し、中間層のフィルタが何を検出しているかを可視化します。さらに、**アブレーション（層・特徴マップの寄与分析）** と **領域隠し（オクルージョン）** による感度解析を通じ、モデル設計改善に結びつく実証的な知見を提示します。

---

### 1. 新規性：この論文の貢献と既存研究との差分

- **DeconvNetによる特徴可視化の確立**: 前向きの畳み込み・プーリングを「近似的に逆」にたどる3段操作（Unpooling→Rectification→Deconvolution）で、入力空間における活性の原因領域を復元。
- **プーリング逆操作（Unpooling with switches）**: Max-pooling時の最大位置（switch）を保存し、逆方向でそこにのみ値を戻す操作を明確化。
- **アブレーションとオクルージョン分析**: どの層・どの特徴が性能に寄与するか、どの画像領域が予測を支えているかを定量評価。設計改善（アーキテクチャ／ハイパーパラメータ）へ還元。

---

### 2. 理論/手法の核心：数式できっちり定式化

#### 記法
- 入力画像を \(x \in \mathbb{R}^{H\times W\times C}\)。
- 層 \(\ell\) の前活性 \(z_{\ell}\)、活性 \(a_{\ell} = \phi(z_{\ell})\)（例: \(\phi=\max(0,\cdot)\)）。
- 畳み込み（ストライドやパディングは省略記法）：
\[
 z_{\ell} = W_{\ell} * a_{\ell-1} + b_{\ell},\quad a_{\ell} = \phi(z_{\ell}).
\]
- Max-pooling を \(P\) とし、各プール窓の最大位置を **switch** 集合 \(S_{\ell}\) として保持。

#### 2.1 DeconvNetによる可視化の3要素
層 \(\ell\) で観察したい上流信号（例えば、\(a_{\ell}\) の単一ユニットや特徴マップの活性）を \(r_{\ell}\) とし、入力空間へ逆投影して \(r_{0}\) を得る。

1) Unpooling（スイッチを用いた逆プーリング）
\[
 r_{\ell}^{\text{unpool}} = U_{S_{\ell}}(r_{\ell}),
\]
ここで \(U_{S_{\ell}}\) は、max-pooling時の最大位置（switch）にのみ値を配置し、それ以外は0とする線形写像。

2) Rectification（層ごとの整流）
\[
 r_{\ell}^{+} = \max(0,\, r_{\ell}^{\text{unpool}}).
\]
DeconvNetでは逆方向でも負値を遮断してスパースかつ直観的なパターンを強調。

3) Deconvolution（転置畳み込みによる逆投影）
\[
 r_{\ell-1} = W_{\ell}^{\top} * r_{\ell}^{+},
\]
ここで \(W_{\ell}^{\top}\) はフィルタの空間反転・チャネル転置に対応（理想的な逆作用素ではないが、構造的対応づけとして用いる）。これを層をまたいで反復し、\(r_0\) を可視化画像とする。

#### 2.2 オクルージョン（領域隠し）による感度解析
画像の局所パッチをスライドさせて隠し（一定値で塗り潰し）、クラススコア低下量で重要度を可視化：
\[
\mathcal{H}_c(i,j) \,=\, S_c(x) - S_c\bigl(\mathcal{O}_{i,j}(x)\bigr),
\]
\(\mathcal{O}_{i,j}\) は中心 \((i,j)\) の \(m\times m\) パッチをオクルードする操作。\(\mathcal{H}_c\) をヒートマップ化することで、予測に重要な領域を特定できる。

#### 2.3 アブレーションによる層・特徴寄与の評価
層 \(\ell\) の一部または全特徴マップをゼロ化して性能変化を測る：
\[
\Delta \text{Acc}_{\ell} \,=\, \text{Acc}(\text{model}) - \text{Acc}(\text{ablated at layer } \ell).
\]
これにより、どの層（や特定の特徴群）が最終精度に強く寄与しているかを定量的に把握できる。

---

### 3. 「キモ」と重要性：本論文の核と影響
- **キモ**: 前向き処理（畳み込み・プーリング・整流）の各段を、情報保存の観点で可能な範囲「逆」に辿ることで、特定ユニット／マップの「入力空間における根拠」を可視化する枠組み（Unpooling with switches + 転置畳み込み + 逆方向整流）。
- **重要性/影響**: 中間表現の解釈を飛躍的に前進させ、アーキテクチャ改善（層深さ・受容野・正則化）の知見を与えた。後続のGuided Backprop, Grad-CAM系、ネットワーク可視化・説明の系譜に強い影響を与えた。

---

### 4. まとめ（要点）
- DeconvNet: \(U_{S_{\ell}}\)（スイッチ付きUnpool）→ \(\max(0,\cdot)\)（整流）→ \(W_{\ell}^{\top} * \cdot\)（転置畳み込み）で入力空間に逆投影。
- オクルージョン: \(\mathcal{H}_c(i,j)=S_c(x)-S_c(\mathcal{O}_{i,j}(x))\) により領域の重要度を測定。
- アブレーション: 層・特徴マップの寄与を精度低下で定量化。

---

### 付録A. スイッチ付きUnpoolingの形式化
Max-pooling 窓 \(\Omega\) 内の最大位置を \(p^*(\Omega)\) とし、対応するスイッチ写像を \(S_{\ell}: \Omega' \to \Omega\) とする（\(\Omega'\) はプール後格子）。すると、
\[
\bigl[U_{S_{\ell}}(r_{\ell})\bigr]_{p} \,=\, \begin{cases}
 r_{\ell}(p'), & \text{if } p = S_{\ell}(p') \\
 0, & \text{otherwise}
\end{cases}
\]
で定義できる。これにより、プーリングで失われた空間配置を最大位置に限定して復元する。

参考: [arXiv:1311.2901](https://arxiv.org/abs/1311.2901)
