# Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps

**著者**: Karen Simonyan, Andrea Vedaldi, Andrew Zisserman  
**公開**: arXiv 2013（v2: 2014）  
**DOI**: 10.48550/arXiv.1312.6034  
**リンク**: [arXiv:1312.6034](https://arxiv.org/abs/1312.6034)

この論文は、ConvNet（CNN）による画像分類モデルに対し、勾配に基づく2種類の可視化手法（クラス画像生成とクラス特異的サリエンシマップ）を提示し、それらがDeconvolutional Network（DeconvNet）［Zeiler et al., 2013］と理論的に接続できることを示します。また、サリエンシマップが弱教師ありの物体局在（セグメンテーション）に利用可能であることを示します。

**Saliency Map（サリエンシマップ）とは**:
- **定義**: 入力画像の各画素（または領域）が、モデルの予測にどれだけ重要かを示すヒートマップ
- **基本的なアイデア**: クラススコア \(S_c(x)\) に対する入力画像 \(x\) の勾配 \(\nabla_x S_c(x)\) を計算し、勾配の大きさが大きい画素ほど「重要」とみなす
- **直感的な説明**: 「この画素を少し変えたら、予測スコアがどれだけ変わるか」を表す。勾配が大きい = その画素が予測に大きく影響する = 重要

**2つの主要な可視化手法**:
1. **クラス画像生成**: クラス \(c\) らしさを最大化する画像を生成（「モデルが"猫"と判断するために必要な視覚的特徴は何か」を可視化）
2. **クラス特異的サリエンシマップ**: 特定の入力画像に対して、どの画素がクラス \(c\) の予測に寄与したかを可視化（「この画像のどこを見て"猫"と判断したか」を可視化）

---

### 1. 新規性：この論文の貢献と既存研究との差分

- **勾配ベースの統一的枠組み**: クラススコアに対する入力画像の勾配を用い、
  - （i）クラス概念を「最大化画像」として再構成する最適化問題、
  - （ii）個別画像に対するクラス特異的サリエンシ（重要度）を得る方法、
  を単一の原理（勾配）で記述。
- **DeconvNet/GUIDED-BPとの接続**: ReLU 逆伝播の取り扱いの違いとして位置づけ、標準BP・DeconvNet・Guided Backpropagation（本論文での定式化）を比較し、関係性を明確化。
- **弱教師あり局在**: サリエンシマップから簡便な後処理で物体領域を推定できることを実証。

---

### 2. 理論/手法の核心：数式できっちり定式化

#### 記法
- 画像をベクトル化して \(x \in \mathbb{R}^d\) とする（RGBはチャンネル次元を含む）。
- クラス \(c\) のスコア関数（ロジット）を \(S_c(x)\) とする。
- 画素座標を \((i,j)\)、チャンネルを \(k\) とする。

#### 2.1 クラス画像生成（クラス概念の可視化）
「クラス \(c\) らしさ」を最大化する画像 \(x\) を求める最適化問題を、L2正則化と画素範囲制約つきで解く：
\[
\max_{x \in [a,b]^d} \; \; \mathcal{J}(x) \;:=\; S_c(x)\; -\; \lambda\,\lVert x \rVert_2^2,
\]
ここで \(\lambda>0\)、画素域 \([a,b]\) は例えば \([0,1]\) または \([0,255]\)。
勾配上昇により反復更新：
\[
\begin{aligned}
 x^{(t+1)} &\leftarrow x^{(t)} + \eta\,\nabla_x\mathcal{J}(x^{(t)}) \\
 &= x^{(t)} + \eta\Bigl( \underbrace{\nabla_x S_c(x^{(t)})}_{\text{順伝播スコアの入力勾配}} - 2\lambda\,x^{(t)} \Bigr), \\
 x^{(t+1)} &\leftarrow \Pi_{[a,b]^d}\bigl(x^{(t+1)}\bigr),
\end{aligned}
\]
\(\Pi\) は画素域への射影（クリッピング）。初期値はノイズ画像などから開始する。

#### 2.2 クラス特異的サリエンシマップ
入力 \(x\) におけるクラス \(c\) のサリエンシは、スコアの入力勾配：
\[
W^{(c)}(x) \;:=\; \nabla_x S_c(x) \;=\; \frac{\partial S_c(x)}{\partial x} \in \mathbb{R}^{d}.
\]
画素 \((i,j)\) に対する強度は、RGB各チャンネル勾配の集約（本論文では最大絶対値が用いられる）：
\[
M^{(c)}(i,j) \;=\; \max_{k\in\{R,G,B\}} \bigl|\, \tfrac{\partial S_c(x)}{\partial x_{i,j,k}} \,\bigr|.
\]
ヒートマップは \(M^{(c)}\) を適宜正規化・平滑化して可視化する。

#### 2.3 ReLU における逆伝播ルールの比較（BP / Deconv / Guided-BP）
活性 \(z_\ell\) に対する ReLU を \(a_\ell = \max(0, z_\ell)\) とし、上流勾配を \(g_{\ell+1}\) とする。下流勾配 \(g_\ell\) の計算は手法で異なる：
- 標準Backprop（BP）
\[
 g_\ell^{\text{BP}} \;=\; \mathbb{1}[z_\ell > 0] \;\odot\; g_{\ell+1}.
\]
- DeconvNet（Zeiler & Fergus, 2013）
\[
 g_\ell^{\text{Deconv}} \;=\; \mathbb{1}[g_{\ell+1} > 0] \;\odot\; g_{\ell+1}.
\]
- Guided Backpropagation（本論文で整理）
\[
 g_\ell^{\text{Guided}} \;=\; \mathbb{1}[z_\ell > 0] \;\odot\; \mathbb{1}[g_{\ell+1} > 0] \;\odot\; g_{\ell+1}.
\]
ここで \(\mathbb{1}[\cdot]\) は要素別のインジケータ、\(\odot\) はHadamard積。これらの違いが、入力勾配（＝サリエンシ）や可視化の見え方の差を生む。

#### 2.4 DeconvNetからSaliency Mapsへの進化

**DeconvNet（Zeiler & Fergus, 2013）のアプローチ**:
- **方法**: 中間層の活性化を入力空間に「逆投影」する（Unpooling → Rectification → Deconvolution）
- **目的**: 特定のユニットや特徴マップが何を検出しているかを可視化
- **計算**: 順伝播時の情報（switch位置など）を保存し、逆方向で復元

**Saliency Maps（Simonyan et al., 2013）の進化点**:

1. **勾配ベースの統一的枠組み**:
   - DeconvNet: 中間層の活性化を逆投影（複雑な操作が必要）
   - Saliency Maps: **単純に勾配 \(\nabla_x S_c(x)\) を計算**（より直接的でシンプル）
   - **利点**: 実装が簡単、計算が高速、理論的に明確

2. **クラス特異的な説明**:
   - DeconvNet: 特定のユニットや特徴マップが何を検出しているかを可視化（「このフィルタは何を見ているか」）
   - Saliency Maps: **特定のクラス予測にどの画素が寄与したか**を可視化（「なぜ"猫"と判断したか」）
   - **利点**: 予測の説明により直接的に関連

3. **ReLU逆伝播の整理**:
   - DeconvNet: 逆伝播時の勾配が正の位置のみ伝播（\(\mathbb{1}[g_{\ell+1} > 0]\)）
   - Saliency Maps: 標準BP、DeconvNet、Guided-BPの3つの方法を統一的に比較・整理
   - **利点**: 異なる可視化手法の関係性を明確化

4. **弱教師あり局在への応用**:
   - DeconvNet: 主に可視化・理解に焦点
   - Saliency Maps: **弱教師ありの物体局在（セグメンテーション）**に利用可能であることを実証
   - **利点**: 実用的な応用範囲の拡大

**主な進化のポイント**:
- **計算の簡素化**: 複雑な逆投影操作から、単純な勾配計算へ
- **目的の明確化**: 中間層の理解から、予測の説明へ
- **理論的統一**: 異なる可視化手法を勾配の観点で統一的に理解
- **実用性の向上**: 弱教師あり局在など、より実用的な応用への展開

#### 2.4 弱教師ありの領域推定
サリエンシマップ \(M^{(c)}\) を閾値処理・連結成分抽出などで後処理し、物体の候補領域（バウンディングボックスやマスク）を推定。クラスラベルのみの監督でも、画像内の位置情報を抽出できることを示す。

---

### 3. 「キモ」と重要性：本論文の核と影響
- **キモ**: 「クラススコアの勾配」による最小限の仮定で、（i）クラス概念の再構成（最大化画像）と（ii）入力画像に対するクラス特異的説明（サリエンシ）を同一原理で与え、さらにReLU逆伝播の取り扱い差（BP/Deconv/Guided）として可視化法を統一的に位置づけた点。
- **重要性/影響**: サリエンシは以後のXAI研究における基本ベースラインとなり、弱教師あり局在やモデルデバッグに広く利用された。単純な一階微分に基づくが、局在性と直観的な可視化品質を両立させた点が実務で有用。

---

### 4. まとめ（要点）
- クラス画像生成：\(\max_x S_c(x) - \lambda\lVert x\rVert_2^2\) を勾配上昇で解く。
- サリエンシ：\(W^{(c)} = \nabla_x S_c(x)\)、画素強度は \(M^{(c)}(i,j)=\max_k |\partial S_c/\partial x_{i,j,k}|\)。
- ReLU逆伝播の3流儀（BP/Deconv/Guided）を統一的に比較・整理。
- サリエンシから弱教師ありの物体領域推定が可能。

---

### 4.5. 他の手法との違いと関係

**Saliency Map vs Grad-CAM**:
- **Saliency Map**: 入力画像の各画素に対する勾配を直接計算。解像度は入力画像と同じ（高解像度）
- **Grad-CAM**: 最終畳み込み層の特徴マップに対する勾配を計算し、空間的にアップサンプル。解像度は低いが、より高次特徴を捉える
- **使い分け**: Saliency Mapは細かい詳細を捉えるが、ノイズが多い。Grad-CAMは粗いが、より意味のある領域を強調

**Saliency Map vs LIME**:
- **Saliency Map**: 勾配ベース、1回の逆伝播で計算可能、微分可能モデルに限定
- **LIME**: サンプリングベース、モデル非依存、多数のサンプルが必要
- **計算コスト**: Saliency Mapの方が高速

**Saliency Map vs Integrated Gradients**:
- **Saliency Map**: 単純な勾配（一階微分）、飽和問題がある可能性
- **Integrated Gradients**: 経路積分（複数の勾配の積分）、飽和問題を緩和
- **精度**: Integrated Gradientsの方が理論的に堅牢

**ReLU逆伝播の違い**:
- **標準Backprop（BP）**: 順伝播時の活性化が正の位置のみ勾配を伝播
- **DeconvNet**: 逆伝播時の勾配が正の位置のみ伝播
- **Guided Backpropagation**: 順伝播と逆伝播の両方が正の位置のみ伝播（よりシャープな可視化）

---

### 4.6. 適用例と使用場面

**主な用途**:
- **モデルデバッグ**: モデルが正しい特徴を見ているか確認
- **弱教師あり局在**: 画像レベルのラベルのみで物体領域を推定
- **バイアス検出**: モデルが不適切な特徴（背景、性別など）に依存していないか確認
- **可視化**: モデルの判断根拠をユーザーに提示

**制限事項**:
- 勾配がゼロになる領域（飽和）では重要度が過小評価される可能性
- ノイズが多く、後処理（平滑化、閾値処理）が必要な場合がある
- 微分可能モデルに限定される

---

### 付録A. 一次近似（テイラー展開）によるサリエンシの導出
入力摂動 \(\delta\) に対する一次近似：
\[
S_c(x+\delta) \;\approx\; S_c(x) \;+\; \nabla_x S_c(x)^{\top}\,\delta.
\]
小さな領域の画素 \((i,j,k)\) の寄与度は、対応する偏導関数の大きさで一次的に測れる。したがって、画素単位のサリエンシ強度を
\[
M^{(c)}(i,j) \;=\; \max_{k\in\{R,G,B\}} \bigl|\, \tfrac{\partial S_c(x)}{\partial x_{i,j,k}} \,\bigr|
\]
と置くのは、線形化に基づく自然な選択である（符号付きマップやL2集約を用いる変種も考えられる）。

### 付録B. 正則化と実装上の注意
- **L2正則化**: クラス画像生成で \(\lambda\lVert x\rVert_2^2\) を用いて高周波成分の発散を抑える。
- **画素域クリッピング**: \([a,b]\) への射影 \(\Pi_{[a,b]^d}\) を各反復で適用し、可視化が実画像域から外れないようにする。
- **実務補足**: 本論文の主眼ではないが、後続実装では更新ステップ間のガウシアン平滑化や微小な総変動（TV）正則化を併用してアーティファクトを抑える設計も一般的である。

参考: [arXiv:1312.6034](https://arxiv.org/abs/1312.6034)
