# Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps

**著者**: Karen Simonyan, Andrea Vedaldi, Andrew Zisserman  
**公開**: arXiv 2013（v2: 2014）  
**DOI**: 10.48550/arXiv.1312.6034  
**リンク**: [arXiv:1312.6034](https://arxiv.org/abs/1312.6034)

この論文は、ConvNet（CNN）による画像分類モデルに対し、勾配に基づく2種類の可視化手法（クラス画像生成とクラス特異的サリエンシマップ）を提示し、それらがDeconvolutional Network（DeconvNet）［Zeiler et al., 2013］と理論的に接続できることを示します。また、サリエンシマップが弱教師ありの物体局在（セグメンテーション）に利用可能であることを示します。

---

### 1. 新規性：この論文の貢献と既存研究との差分

- **勾配ベースの統一的枠組み**: クラススコアに対する入力画像の勾配を用い、
  - （i）クラス概念を「最大化画像」として再構成する最適化問題、
  - （ii）個別画像に対するクラス特異的サリエンシ（重要度）を得る方法、
  を単一の原理（勾配）で記述。
- **DeconvNet/GUIDED-BPとの接続**: ReLU 逆伝播の取り扱いの違いとして位置づけ、標準BP・DeconvNet・Guided Backpropagation（本論文での定式化）を比較し、関係性を明確化。
- **弱教師あり局在**: サリエンシマップから簡便な後処理で物体領域を推定できることを実証。

---

### 2. 理論/手法の核心：数式できっちり定式化

#### 記法
- 画像をベクトル化して \(x \in \mathbb{R}^d\) とする（RGBはチャンネル次元を含む）。
- クラス \(c\) のスコア関数（ロジット）を \(S_c(x)\) とする。
- 画素座標を \((i,j)\)、チャンネルを \(k\) とする。

#### 2.1 クラス画像生成（クラス概念の可視化）
「クラス \(c\) らしさ」を最大化する画像 \(x\) を求める最適化問題を、L2正則化と画素範囲制約つきで解く：
\[
\max_{x \in [a,b]^d} \; \; \mathcal{J}(x) \;:=\; S_c(x)\; -\; \lambda\,\lVert x \rVert_2^2,
\]
ここで \(\lambda>0\)、画素域 \([a,b]\) は例えば \([0,1]\) または \([0,255]\)。
勾配上昇により反復更新：
\[
\begin{aligned}
 x^{(t+1)} &\leftarrow x^{(t)} + \eta\,\nabla_x\mathcal{J}(x^{(t)}) \\
 &= x^{(t)} + \eta\Bigl( \underbrace{\nabla_x S_c(x^{(t)})}_{\text{順伝播スコアの入力勾配}} - 2\lambda\,x^{(t)} \Bigr), \\
 x^{(t+1)} &\leftarrow \Pi_{[a,b]^d}\bigl(x^{(t+1)}\bigr),
\end{aligned}
\]
\(\Pi\) は画素域への射影（クリッピング）。初期値はノイズ画像などから開始する。

#### 2.2 クラス特異的サリエンシマップ
入力 \(x\) におけるクラス \(c\) のサリエンシは、スコアの入力勾配：
\[
W^{(c)}(x) \;:=\; \nabla_x S_c(x) \;=\; \frac{\partial S_c(x)}{\partial x} \in \mathbb{R}^{d}.
\]
画素 \((i,j)\) に対する強度は、RGB各チャンネル勾配の集約（本論文では最大絶対値が用いられる）：
\[
M^{(c)}(i,j) \;=\; \max_{k\in\{R,G,B\}} \bigl|\, \tfrac{\partial S_c(x)}{\partial x_{i,j,k}} \,\bigr|.
\]
ヒートマップは \(M^{(c)}\) を適宜正規化・平滑化して可視化する。

#### 2.3 ReLU における逆伝播ルールの比較（BP / Deconv / Guided-BP）
活性 \(z_\ell\) に対する ReLU を \(a_\ell = \max(0, z_\ell)\) とし、上流勾配を \(g_{\ell+1}\) とする。下流勾配 \(g_\ell\) の計算は手法で異なる：
- 標準Backprop（BP）
\[
 g_\ell^{\text{BP}} \;=\; \mathbb{1}[z_\ell > 0] \;\odot\; g_{\ell+1}.
\]
- DeconvNet（Zeiler & Fergus, 2013）
\[
 g_\ell^{\text{Deconv}} \;=\; \mathbb{1}[g_{\ell+1} > 0] \;\odot\; g_{\ell+1}.
\]
- Guided Backpropagation（本論文で整理）
\[
 g_\ell^{\text{Guided}} \;=\; \mathbb{1}[z_\ell > 0] \;\odot\; \mathbb{1}[g_{\ell+1} > 0] \;\odot\; g_{\ell+1}.
\]
ここで \(\mathbb{1}[\cdot]\) は要素別のインジケータ、\(\odot\) はHadamard積。これらの違いが、入力勾配（＝サリエンシ）や可視化の見え方の差を生む。

#### 2.4 弱教師ありの領域推定
サリエンシマップ \(M^{(c)}\) を閾値処理・連結成分抽出などで後処理し、物体の候補領域（バウンディングボックスやマスク）を推定。クラスラベルのみの監督でも、画像内の位置情報を抽出できることを示す。

---

### 3. 「キモ」と重要性：本論文の核と影響
- **キモ**: 「クラススコアの勾配」による最小限の仮定で、（i）クラス概念の再構成（最大化画像）と（ii）入力画像に対するクラス特異的説明（サリエンシ）を同一原理で与え、さらにReLU逆伝播の取り扱い差（BP/Deconv/Guided）として可視化法を統一的に位置づけた点。
- **重要性/影響**: サリエンシは以後のXAI研究における基本ベースラインとなり、弱教師あり局在やモデルデバッグに広く利用された。単純な一階微分に基づくが、局在性と直観的な可視化品質を両立させた点が実務で有用。

---

### 4. まとめ（要点）
- クラス画像生成：\(\max_x S_c(x) - \lambda\lVert x\rVert_2^2\) を勾配上昇で解く。
- サリエンシ：\(W^{(c)} = \nabla_x S_c(x)\)、画素強度は \(M^{(c)}(i,j)=\max_k |\partial S_c/\partial x_{i,j,k}|\)。
- ReLU逆伝播の3流儀（BP/Deconv/Guided）を統一的に比較・整理。
- サリエンシから弱教師ありの物体領域推定が可能。

---

### 付録A. 一次近似（テイラー展開）によるサリエンシの導出
入力摂動 \(\delta\) に対する一次近似：
\[
S_c(x+\delta) \;\approx\; S_c(x) \;+\; \nabla_x S_c(x)^{\top}\,\delta.
\]
小さな領域の画素 \((i,j,k)\) の寄与度は、対応する偏導関数の大きさで一次的に測れる。したがって、画素単位のサリエンシ強度を
\[
M^{(c)}(i,j) \;=\; \max_{k\in\{R,G,B\}} \bigl|\, \tfrac{\partial S_c(x)}{\partial x_{i,j,k}} \,\bigr|
\]
と置くのは、線形化に基づく自然な選択である（符号付きマップやL2集約を用いる変種も考えられる）。

### 付録B. 正則化と実装上の注意
- **L2正則化**: クラス画像生成で \(\lambda\lVert x\rVert_2^2\) を用いて高周波成分の発散を抑える。
- **画素域クリッピング**: \([a,b]\) への射影 \(\Pi_{[a,b]^d}\) を各反復で適用し、可視化が実画像域から外れないようにする。
- **実務補足**: 本論文の主眼ではないが、後続実装では更新ステップ間のガウシアン平滑化や微小な総変動（TV）正則化を併用してアーティファクトを抑える設計も一般的である。

参考: [arXiv:1312.6034](https://arxiv.org/abs/1312.6034)
