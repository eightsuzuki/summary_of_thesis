# Gradient Descent: 勾配降下法

**勾配降下法（Gradient Descent）**は、目的関数の勾配（一階微分）の情報を用いて、関数の最小値に向かって反復的に移動する局所探索手法です。機械学習や最適化において最も基本的で広く使われている手法の一つです。

---

### 1. 基本的なアイデア

**勾配の方向**:
- **勾配**: 関数の最も急な上昇方向
- **負の勾配**: 関数の最も急な下降方向
- **反復更新**: 負の勾配方向に移動することで最小値に近づく

---

### 2. アルゴリズムの流れ

```
1. 初期点 x_0 を設定
2. 終了条件を満たすまで繰り返し:
   a. 勾配 ∇f(x_t) を計算
   b. ステップサイズ α_t を決定
   c. x_{t+1} = x_t - α_t ∇f(x_t) で更新
3. 最適解 x* を返す
```

---

### 3. 数式による定式化

#### 3.1 基本的な更新式

目的関数 \(f(x)\) を最小化：
\[
x_{t+1} = x_t - \alpha_t \nabla f(x_t)
\]

ここで：
- \(\alpha_t > 0\): ステップサイズ（学習率）
- \(\nabla f(x_t)\): 点 \(x_t\) での勾配

#### 3.2 ステップサイズの選択

**固定ステップサイズ**:
\[
\alpha_t = \alpha \quad \text{(定数)}
\]

**適応的ステップサイズ**:
\[
\alpha_t = \frac{\alpha}{\sqrt{t+1}} \quad \text{(時間減衰)}
\]

**最適ステップサイズ（直線探索）**:
\[
\alpha_t = \arg\min_{\alpha > 0} f(x_t - \alpha \nabla f(x_t))
\]

#### 3.3 収束条件

勾配のノルムが十分小さいとき収束：
\[
\|\nabla f(x_t)\| < \epsilon
\]

---

### 4. XAIへの応用

#### 4.1 説明の最適化

**問題**: 最適な説明を生成する

**Gradient Descentの適用**:
- **目的関数**: 説明の品質（忠実度、簡潔性）
- **変数**: 説明のパラメータ（特徴の重みなど）
- **勾配**: 説明の品質に対するパラメータの感度
- **目的**: 高品質な説明を見つける

#### 4.2 特徴の重要度の推定

**問題**: 特徴の重要度を推定する

**Gradient Descentの適用**:
- **目的関数**: 予測誤差
- **変数**: 特徴の重み
- **勾配**: 特徴の重要度
- **目的**: 特徴の重要度を推定

#### 4.3 反事実説明の生成

**問題**: 予測を変える最小の変更を見つける

**Gradient Descentの適用**:
- **目的関数**: 予測の変化量 + 変更のコスト
- **変数**: 入力の変更量
- **勾配**: 予測に対する入力の感度
- **目的**: 最小の変更で予測を変える

---

### 5. 利点と欠点

**利点**:
- 実装が簡単
- 計算コストが低い
- 大規模な問題にも適用可能
- 微分可能な関数に広く適用可能

**欠点**:
- 局所最適解に陥る可能性がある
- ステップサイズの選択が重要
- 収束が遅い場合がある
- 非凸問題では最適解が保証されない

---

### 6. 実装上の注意点

- **ステップサイズ**: 大きすぎると発散、小さすぎると収束が遅い
- **初期値**: 局所最適解に依存するため、初期値の選択が重要
- **正規化**: 勾配のスケールを調整
- **収束判定**: 勾配のノルムや目的関数の変化量で判定

---

### 7. バリエーション

- **標準GD**: 上記の基本アルゴリズム
- **確率的勾配降下法（SGD）**: サンプルごとに勾配を計算
- **ミニバッチGD**: バッチごとに勾配を計算
- **モメンタム**: 過去の更新を考慮
- **Adam**: 適応的モメンタムと学習率

---

### 8. 参考文献

- Cauchy, A. (1847). Méthode générale pour la résolution des systèmes d'équations simultanées. *Comptes Rendus de l'Académie des Sciences*, 25, 536-538.
- Nesterov, Y. (1983). A method for solving the convex programming problem with convergence rate O(1/k^2). *Doklady Akademii Nauk SSSR*, 269, 543-547.

---

### 9. まとめ

勾配降下法は、最も基本的で広く使われている局所探索手法です。XAIにおいては、説明の最適化、特徴の重要度の推定、反事実説明の生成などに応用されています。実装が簡単で計算コストが低いため、実用的な手法として広く使われています。

