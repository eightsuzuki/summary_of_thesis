# 文書-単語行列の特異値分解（SVD）の詳細解説

## 概要

特異値分解（Singular Value Decomposition, SVD）は、任意の行列を3つの行列の積に分解する線形代数の基本定理です。文書-単語行列にSVDを適用することで、高次元の疎な表現から低次元の密な意味表現を抽出できます。

## SVDの数学的定義

### 基本定理

任意の $m \times n$ 行列 $A$ は、以下のように分解できます：

$$
A = U \Sigma V^T
$$

ここで：
- $U \in \mathbb{R}^{m \times m}$：左特異ベクトル行列（直交行列）
- $\Sigma \in \mathbb{R}^{m \times n}$：特異値の対角行列
- $V \in \mathbb{R}^{n \times n}$：右特異ベクトル行列（直交行列）

### 特異値の性質

特異値 $\sigma_1, \sigma_2, \ldots, \sigma_r$（$r = \min(m,n)$）は以下の性質を持ちます：

1. **非負性**: $\sigma_i \geq 0$ for all $i$
2. **降順**: $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r \geq 0$
3. **ランク**: 非ゼロ特異値の数が行列のランク

### 行列の構造

**特異値行列 $\Sigma$**:
$$
\Sigma = \begin{bmatrix}
\sigma_1 & 0 & \cdots & 0 & 0 & \cdots & 0 \\
0 & \sigma_2 & \cdots & 0 & 0 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \sigma_r & 0 & \cdots & 0 \\
0 & 0 & \cdots & 0 & 0 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 0 & 0 & \cdots & 0
\end{bmatrix}
$$

## 文書-単語行列でのSVD

### 行列の構築

文書集合 $D = \{d_1, d_2, \ldots, d_m\}$ と語彙 $V = \{w_1, w_2, \ldots, w_n\}$ から、$m \times n$ の文書-単語行列 $A$ を構築します：

$$
A_{ij} = \text{weight}(w_j, d_i)
$$

通常、TF-IDF値が使用されます。

### SVDの適用

$$
A = U \Sigma V^T
$$

**各行列の意味**:
- $U$：文書空間の基底（文書の「意味的方向」）
- $\Sigma$：各方向の「重要度」（特異値）
- $V$：単語空間の基底（単語の「意味的方向」）

### 次元削減

意味空間の次元 $k$（通常 $k \ll \min(m,n)$）を選択し、上位 $k$ 個の特異値のみを保持：

$$
A_k = U_k \Sigma_k V_k^T
$$

ここで：
- $U_k \in \mathbb{R}^{m \times k}$：上位 $k$ 個の左特異ベクトル
- $\Sigma_k \in \mathbb{R}^{k \times k}$：上位 $k$ 個の特異値
- $V_k \in \mathbb{R}^{n \times k}$：上位 $k$ 個の右特異ベクトル

## 具体例

### 簡単な例

文書集合：
- 文書1: "cat sat on mat"
- 文書2: "dog ran in park"
- 文書3: "cat and dog are friends"

語彙: {cat, dog, sat, ran, on, in, mat, park, and, are, friends}

**文書-単語行列 $A$**（TF-IDF値）:
```
     cat  dog  sat  ran  on   in   mat  park and  are  friends
d1   0.5  0    0.5  0    0.5  0    0.5  0    0    0    0
d2   0    0.5  0    0.5  0    0.5  0    0.5  0    0    0
d3   0.3  0.3  0    0    0    0    0    0    0.3  0.3  0.3
```

**SVD分解**:
$$
A = U \Sigma V^T
$$

**特異値**（例）:
- $\sigma_1 = 1.2$（最も重要な意味方向）
- $\sigma_2 = 0.8$（2番目に重要な意味方向）
- $\sigma_3 = 0.3$（3番目に重要な意味方向）
- その他は0に近い

### 次元削減（$k=2$）

$$
A_2 = U_2 \Sigma_2 V_2^T
$$

**埋め込みの抽出**:
- 単語埋め込み: $V_2 \Sigma_2^{1/2}$
- 文書埋め込み: $U_2 \Sigma_2^{1/2}$

## SVDの幾何学的解釈

### 線形変換としてのSVD

SVDは、行列 $A$ による線形変換を以下の3段階に分解します：

1. **回転**: $V^T$ による回転
2. **スケーリング**: $\Sigma$ による各軸方向のスケーリング
3. **回転**: $U$ による回転

### 最適近似の性質

SVDは、**最良の低ランク近似**を提供します：

$$
A_k = \arg\min_{\text{rank}(B) \leq k} ||A - B||_F
$$

ここで、$||\cdot||_F$ はフロベニウスノルムです。

## 計算アルゴリズム

### 基本的なアルゴリズム

1. **固有値分解**: $A^T A$ と $A A^T$ の固有値分解
2. **特異値**: $\sigma_i = \sqrt{\lambda_i}$（$\lambda_i$ は固有値）
3. **特異ベクトル**: 固有ベクトルから計算

### 効率的なアルゴリズム

- **Lanczos法**: 大規模疎行列用
- **Randomized SVD**: 近似SVD
- **Incremental SVD**: オンライン更新

## LSAでのSVDの役割

### 意味空間の構築

SVDにより、以下の意味空間が構築されます：

1. **第1主成分**: 最も重要な意味的方向（全体的な文書の傾向）
2. **第2主成分**: 2番目に重要な意味的方向（特定のトピック）
3. **第3主成分**: 3番目に重要な意味的方向（細かい分類）

### ノイズ除去

小さな特異値（ノイズ）を除去することで、本質的な意味情報のみを保持：

$$
\text{信号} = \sum_{i=1}^{k} \sigma_i \mathbf{u}_i \mathbf{v}_i^T
$$

$$
\text{ノイズ} = \sum_{i=k+1}^{r} \sigma_i \mathbf{u}_i \mathbf{v}_i^T
$$

## 特異値の解釈

### 特異値の意味

- **大きい特異値**: 重要な意味的方向（多くの文書・単語が関与）
- **小さい特異値**: 細かい意味的方向（少数の文書・単語のみ）
- **ゼロ特異値**: 冗長な情報（線形従属）

### 特異値の分布

通常、特異値は以下のような分布を示します：

```
σ₁ = 10.5  ████████████████████████████████████████
σ₂ = 8.2   ████████████████████████████████
σ₃ = 5.1   ████████████████████
σ₄ = 2.3   ████████
σ₅ = 0.8   ███
σ₆ = 0.1   █
...
```

## 計算の複雑度

### 時間計算量

- **完全SVD**: $O(\min(mn^2, m^2n))$
- **部分SVD**: $O(mnk)$（上位 $k$ 個の特異値のみ）

### 空間計算量

- **完全SVD**: $O(m^2 + n^2)$
- **部分SVD**: $O(mk + nk)$

## 実装の注意点

### 数値的安定性

- **正規化**: 行列の正規化による数値安定性の向上
- **閾値設定**: 小さな特異値の切り捨て
- **反復法**: 大規模行列での効率的な計算

### メモリ効率

- **疎行列**: 疎行列ライブラリの活用
- **ストリーミング**: 大規模データの分割処理
- **並列化**: 複数コアでの並列計算

## SVDの限界

### 線形性の制約

- **非線形関係**: 非線形な意味関係を捉えられない
- **文脈依存**: 文脈による意味変化に対応できない

### 計算コスト

- **大規模データ**: 数百万文書・単語での計算が困難
- **リアルタイム**: 新しい文書の追加時の再計算コスト

### 解釈性

- **特異ベクトル**: 意味解釈が困難
- **次元選択**: 最適な $k$ の選択が主観的

## 現代的な発展

### 近似手法

- **Randomized SVD**: 確率的近似
- **Nyström法**: カーネル行列の近似
- **Sketching**: データの圧縮による近似

### 非線形拡張

- **Kernel PCA**: カーネル関数による非線形拡張
- **Autoencoder**: ニューラルネットワークによる非線形次元削減
- **t-SNE/UMAP**: 非線形可視化手法

SVDは、文書-単語行列から意味空間を抽出する強力な数学的ツールであり、LSAの核心技術として、現代の埋め込み手法の基礎を築いています。
