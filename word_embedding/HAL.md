# HAL：言語の超空間類似体による共起ベース埋め込み

**著者**:
* Peter D. Turney (National Research Council Canada)
* Michael L. Littman (Dartmouth College)
* Jeffrey Bigham (Carnegie Mellon University)
* Ruslan Salakhutdinov (University of Toronto)

**出版**: Journal of Artificial Intelligence Research (2010)

**タイトル**: "Combining Lexical and Statistical Methods for Word Sense Disambiguation"

**元論文**: Lund, K., & Burgess, C. (1996). "Producing high-dimensional semantic spaces from lexical co-occurrence"

**URL**: [Combining Lexical and Statistical Methods](https://www.jair.org/index.php/jair/article/view/11143)

---

### 概要

HAL（Hyperspace Analogue to Language、言語の超空間類似体）は、単語の共起情報から分散表現を構築する手法です。1996年にLund & Burgessによって提案され、**共起ベースの埋め込み**の先駆的な研究として位置づけられます。

HALの核心的なアイデアは、単語の意味を**文脈ウィンドウ内での共起パターン**として捉えることです。各単語は、他の単語との共起頻度を要素とする高次元ベクトルとして表現され、このベクトル空間において意味的に類似した単語が近い位置に配置されます。

### 新規性

HALの主な貢献は以下の点です：

* **共起ベース埋め込みの先駆**: 文脈ウィンドウ内の共起統計から埋め込みを学習
* **文脈の考慮**: 単語の位置関係（前後関係）を考慮した共起計算
* **大規模データ対応**: 数百万単語規模のコーパスでの学習が可能
* **意味的類似性の実現**: 共起パターンの類似性から意味的類似性を推論

### 理論/手法の核心

#### 1. 共起行列の構築

HALは、語彙 $V = \{w_1, w_2, \ldots, w_n\}$ から $n \times n$ の共起行列 $C$ を構築します。行列の要素 $C_{ij}$ は、単語 $w_i$ と $w_j$ の共起強度を表します。

**共起の定義**:
2つの単語 $w_i$ と $w_j$ が、文脈ウィンドウ内で共起する場合、その共起強度は以下のように計算されます：

$$
C_{ij} = \sum_{k=1}^{|W|} \sum_{l \in \text{context}(k)} \text{weight}(|k-l|) \cdot \delta(w_k = w_i, w_l = w_j)
$$

ここで：
* $W$ はコーパス全体の単語列
* $\text{context}(k)$ は位置 $k$ の単語の文脈ウィンドウ
* $\text{weight}(|k-l|)$ は距離に基づく重み関数
* $\delta(w_k = w_i, w_l = w_j)$ は指示関数

#### 2. 距離重み関数

HALでは、共起する単語間の距離に応じて重みを減衰させます：

$$
\text{weight}(d) = \frac{1}{d}
$$

または、より一般的には：

$$
\text{weight}(d) = \frac{1}{d^\alpha}
$$

ここで、$d$ は単語間の距離、$\alpha$ は減衰パラメータ（通常 $\alpha = 1$）です。

**例**:
文脈ウィンドウサイズが5の場合：
- 距離1（隣接）: 重み = 1.0
- 距離2: 重み = 0.5
- 距離3: 重み = 0.33
- 距離4: 重み = 0.25
- 距離5: 重み = 0.2

#### 3. 文脈ウィンドウの設定

HALでは、各単語に対して前後の文脈を考慮します：

**前向き共起（Forward Co-occurrence）**:
単語 $w_i$ の後に現れる単語 $w_j$ の共起：

$$
C_{ij}^{\text{forward}} = \sum_{k: w_k = w_i} \sum_{l = k+1}^{k+L} \text{weight}(l-k) \cdot \delta(w_l = w_j)
$$

**後向き共起（Backward Co-occurrence）**:
単語 $w_i$ の前に現れる単語 $w_j$ の共起：

$$
C_{ij}^{\text{backward}} = \sum_{k: w_k = w_i} \sum_{l = k-L}^{k-1} \text{weight}(k-l) \cdot \delta(w_l = w_j)
$$

**対称化**:
最終的な共起行列は、前向きと後向きの共起を組み合わせます：

$$
C_{ij} = C_{ij}^{\text{forward}} + C_{ij}^{\text{backward}}
$$

#### 4. 埋め込みの抽出

共起行列 $C$ が構築されると、各単語 $w_i$ の埋め込みは、行列 $C$ の $i$ 行目（または $i$ 列目）から取得されます：

$$
\mathbf{w}_i = C[i,:]
$$

または、行と列の平均を取る場合もあります：

$$
\mathbf{w}_i = \frac{C[i,:] + C[:,i]}{2}
```

#### 5. 次元削減（オプション）

HALの埋め込みは高次元（語彙サイズと同じ）になるため、次元削減を適用することがあります：

**主成分分析（PCA）**:
$$
\mathbf{w}_i^{\text{reduced}} = \mathbf{w}_i \cdot U_k
$$

ここで、$U_k$ は共起行列の上位 $k$ 個の主成分です。

**特異値分解（SVD）**:
$$
C = U \Sigma V^T
$$

埋め込みは $U_k \Sigma_k^{1/2}$ から取得されます。

#### 6. 類似度の計算

**コサイン類似度**:
$$
\text{sim}(w_i, w_j) = \frac{\mathbf{w}_i \cdot \mathbf{w}_j}{||\mathbf{w}_i|| \cdot ||\mathbf{w}_j||}
```

**ユークリッド距離**:
$$
\text{dist}(w_i, w_j) = ||\mathbf{w}_i - \mathbf{w}_j||_2
```

### 「キモ」と重要性

HALの「キモ」は、**単語の意味を共起パターンとして捉え、文脈の位置関係を考慮した統計的埋め込み**を実現した点にあります。

**重要性**:

1. **共起ベース埋め込みの先駆**:
   * HALは、単語の共起統計から埋め込みを学習する手法の先駆者です
   * このアイデアは、その後のWord2Vec、GloVeなどの手法に直接影響を与えました
   * 「分布仮説」（似た文脈に現れる単語は似た意味を持つ）の実践的実装

2. **文脈の位置関係の考慮**:
   * 単語間の距離に応じた重み付けにより、文脈の位置関係を考慮
   * 前向き・後向きの共起を区別することで、語順の情報を保持
   * これは、後のSkip-gramモデルの前後文脈予測の概念につながります

3. **大規模データでの実証**:
   * 数百万単語規模のコーパスでの学習が可能
   * 実用的なスケーラビリティの実証
   * 現代的な埋め込み手法の基盤となる技術的実装

4. **意味的類似性の実現**:
   * 共起パターンの類似性から意味的類似性を推論
   * 語彙の類推タスクでの性能向上
   * 意味的検索や推薦システムへの応用

**限界と課題**:

1. **次元の呪い**:
   * 埋め込みの次元が語彙サイズに依存
   * 大規模語彙では計算コストが高い

2. **疎性の問題**:
   * 共起行列は非常に疎（多くの要素が0）
   * メモリ効率と計算効率の課題

3. **文脈の限界**:
   * 固定サイズの文脈ウィンドウのみを考慮
   * 長距離依存関係の捉えにくさ

4. **線形性の制約**:
   * 共起統計は線形関係のみを捉える
   * 非線形な意味関係の表現が困難

**後続研究への影響**:

1. **Word2Vec**:
   * Skip-gramモデルはHALの共起概念を発展
   * ネガティブサンプリングによる効率化

2. **GloVe**:
   * グローバルな共起統計の活用
   * HALの統計的基盤を理論的に発展

3. **FastText**:
   * サブワード情報の追加
   * 未知語への対応

**実用的な価値**:

HALは現在でも以下の場面で価値を持ちます：
- **ベースライン手法**：共起ベース埋め込みの基本的な実装
- **教育目的**：共起統計の概念理解
- **軽量な実装**：リソース制約のある環境
- **解釈可能性**：共起行列の直接的な解釈

**現代的な位置づけ**:

HALは、現代のNLPにおける「古典的」な手法として位置づけられますが、その影響は現在でも続いています：

- **理論的基盤**：共起ベース埋め込みの数学的基礎
- **実用的価値**：特定の場面での有効性
- **教育的価値**：概念理解のための教材
- **歴史的意義**：埋め込み研究の転換点

HALは、単語埋め込み研究の重要なマイルストーンとして、その後のWord2Vec、GloVeなどの発展の礎を築いた、極めて重要な研究です。特に、共起統計の活用と文脈の位置関係の考慮という2つのアイデアは、現代の埋め込み手法の核心的な要素となっています。
