# ConvKB: 知識ベース補完のための畳み込みニューラルネットワーク

**著者**:
* Dai Quoc Nguyen (PRaDA Centre, Deakin University, Australia)
* Tu Dinh Nguyen (PRaDA Centre, Deakin University, Australia)
* Dinh Phung (PRaDA Centre, Deakin University, Australia)
* Wahid Soufian (PRaDA Centre, Deakin University, Australia)

**arXiv**: [arXiv:1712.02121](https://arxiv.org/abs/1712.02121)

---

### 概要

この論文では、知識ベース（Knowledge Base, KB）補完タスクのために、**畳み込みニューラルネットワーク (CNN) を用いた新しいモデル「ConvKB」**が提案されています。先行研究であるConvEと同様にCNNを活用しますが、ConvEがヘッドエンティティと関係を2Dにリシェイプして結合するのに対し、ConvKBはトリプル $(h, r, t)$ の3つの要素であるエンティティ埋め込み $\mathbf{h}$、関係埋め込み $\mathbf{r}$、テールエンティティ埋め込み $\mathbf{t}$ を直接連結して、1DのシーケンスとしてCNNに入力します。これにより、トリプルの各要素間の共通の特徴や多様なパターンを捉え、既存の埋め込みモデルの性能を上回る結果を示しています。

### 新規性

ConvKBの主な新規性とその貢献は以下の点にあります。

1.  **トリプル全体を1Dシーケンスとして直接CNNに入力**:
    * ConvEがヘッドエンティティと関係を2Dに整形して結合していたのに対し、ConvKBはトリプルを構成する3つの埋め込みベクトル $\mathbf{h}, \mathbf{r}, \mathbf{t}$ を直接連結し、これを1Dの入力シーケンスとしてCNNに与えます。
    * このアプローチにより、トリプルの各要素間（例: $h$ と $r$、 $r$ と $t$、 $h$ と $t$）の潜在的な関連性や特徴を、畳み込みフィルタを通じて同時にかつ統一的に学習することが可能になります。これは、トリプル全体の構造的特徴を直接捕捉しようとする試みです。

2.  **各次元間の共通特徴と多様なパターン抽出**:
    * 畳み込みフィルタは、連結された埋め込みベクトルの様々な位置をスキャンし、各次元間の局所的な特徴や、異なる種類の隠れたパターンを自動的に抽出します。これにより、モデルはトリプルのより深いセマンティックな関係性を学習することができます。
    * 例えば、関係の種類に応じてエンティティの特定の次元が活性化されるような複雑な相互作用を捕捉できるようになります。

3.  **高いパラメータ効率と優れた性能**:
    * CNNの特性により、ConvKBは比較的少ないパラメータで高い表現能力を実現します。これは、大規模な知識グラフに適用する際に非常に有利です。
    * 既存の多くの埋め込みモデル（TransE, TransH, TransR, DistMult, ComplEx, ConvEなど）と比較して、特にリンク予測タスクにおいて一貫して優れた性能を達成しました。

4.  **説明可能性の可能性**:
    * CNNの出力である特徴マップを分析することで、モデルがトリプルのどの部分に注目してスコアを計算しているかをある程度解釈できる可能性を秘めています。

### 理論/手法の核心

ConvKBモデルは、各エンティティ $e \in \mathcal{E}$ と各関係 $r \in \mathcal{L}$ を、同じ次元 $k$ の低次元実数ベクトル空間 $\mathbb{R}^k$ に埋め込みます。

1.  **埋め込みの連結**:
    * トリプル $(h, r, t)$ に対応するエンティティ埋め込み $\mathbf{h} \in \mathbb{R}^k$、関係埋め込み $\mathbf{r} \in \mathbb{R}^k$、テールエンティティ埋め込み $\mathbf{t} \in \mathbb{R}^k$ を、順番に横方向に連結します。これにより、入力シーケンス $\mathbf{x} \in \mathbb{R}^{3k}$ が作成されます。

    $$
    \mathbf{x} = [\mathbf{h}; \mathbf{r}; \mathbf{t}]
    $$
    ここで $;$ は連結操作を表します。

2.  **畳み込み層 (Convolutional Layer)**:
    * 連結された入力シーケンス $\mathbf{x}$ に対して、複数の1D畳み込みフィルタ $\mathbf{\omega} \in \mathbb{R}^{w}$ を適用します。ここで $w$ はフィルタの窓幅です。
    * 各フィルタは、シーケンス上の特徴を抽出し、特徴マップを生成します。

    $$
    \mathbf{c}_j = \text{relu}(\mathbf{x}[i:i+w-1] \cdot \mathbf{\omega}_j + b_j)
    $$
    * $\text{relu}(\cdot)$ はReLU活性化関数です。
    * 異なるフィルタから生成された特徴マップを連結し、特徴ベクトル $\mathbf{c} \in \mathbb{R}^{N_{filters} \times (3k-w+1)}$ を形成します（プーリング層を挟むこともあります）。

3.  **プロジェクション層 (Projection Layer)**:
    * 畳み込み層の出力から得られた特徴ベクトル $\mathbf{c}$ を、全結合層（線形変換）を介して最終的なスコアリングに用いる次元に変換します。

    $$
    \mathbf{s} = \text{softmax}(\mathbf{W}_p \mathbf{c} + \mathbf{b}_p)
    $$
    * $\mathbf{W}_p$ は重み行列、$\mathbf{b}_p$ はバイアスベクトルです。
    * ここで $\mathbf{s}$ は、トリプルが正しい確率、またはトリプルのスコアを直接表すベクトルとなります。

4.  **スコアリング関数**:
    * 最終的なスコアは、プロジェクション層の出力に基づいて決定されます。論文では、各トリプルに対応する単一のスコアを予測するために、このベクトル $\mathbf{s}$ の特定の部分を利用したり、softmaxの出力を直接確率として利用したりします。

    $$
    f(h, r, t) = \mathbf{s}_{\text{predicted}}
    $$

5.  **損失関数**:
    * 学習は、正しいトリプルと破損したトリプルの両方に対して、二項分類の枠組みでロジスティック損失（または二項クロスエントロピー損失）を用いて行われます。

    $$
    \mathcal{L} = - \sum_{(h,r,t) \in S \cup S'} \left[ y_{(h,r,t)} \log(\sigma(f(h,r,t))) + (1-y_{(h,r,t)}) \log(1 - \sigma(f(h,r,t))) \right]
    $$
    * $S$: 正しいトリプルのセット。
    * $S'$: 破損した（負例の）トリプルのセット。
    * $y_{(h,r,t)}$: トリプル $(h,r,t)$ が正例であれば1、負例であれば0となるラベル。
    * $\sigma(x) = 1 / (1 + \exp(-x))$: シグモイド関数。

### 「キモ」と重要性

ConvKBの「キモ」は、**知識グラフのトリプル $(h, r, t)$ を構成するエンティティと関係の埋め込みを直接連結した1Dシーケンスとして捉え、そこに畳み込みネットワークを適用することで、トリプル全体の構造的かつセマンティックなパターンを包括的に学習する**という点にあります。これにより、各要素間の複雑な相互作用を、手動での特徴エンジニアリングなしに自動的に抽出できるようになりました。

このアイデアの重要性は以下の点に集約されます。

* **トリプル全体の包括的特徴学習**: ConvEがヘッドと関係のペアに焦点を当てていたのに対し、ConvKBはトリプルを構成する3つの要素すべてを同時に考慮に入れます。これにより、トリプル全体の整合性や、エンティティと関係の間の多様な依存関係をより深く理解できます。
* **表現能力と効率性のバランス**: CNNの活用により、比較的少ないパラメータで高い表現能力を実現し、大規模な知識グラフにもスケーラブルに適用できるというメリットがあります。これは、モデルが大規模なデータセットで効果的に学習し、高精度を達成するために重要です。
* **汎用性と堅牢性**: ConvKBは、比較的シンプルなアーキテクチャでありながら、様々な知識グラフデータセットやリンク予測タスクにおいて、既存の多くのSOTAモデルに対して優れた性能を示しました。これは、そのアプローチが知識グラフの多様な特性に対して汎用性と堅牢性を持つことを示唆しています。
* **深層学習の知識グラフへの応用拡大**: ConvEに続き、ConvKBもCNNが知識グラフのリンク予測において非常に効果的であることを再確認しました。これは、知識グラフ埋め込みの分野における深層学習モデルのさらなる探求と発展を促進する重要な成果となりました。

ConvKBは、そのシンプルながらも効果的なCNNベースのアプローチにより、知識グラフの補完タスクにおける性能向上に貢献し、この分野における深層学習の応用をさらに発展させた重要なモデルであると言えます。
